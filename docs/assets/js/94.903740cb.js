(window.webpackJsonp=window.webpackJsonp||[]).push([[94],{521:function(e,t,n){"use strict";n.r(t);var a=n(56),i=Object(a.a)({},(function(){var e=this,t=e.$createElement,n=e._self._c||t;return n("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[n("h2",{attrs:{id:"_1-overview"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1-overview"}},[e._v("#")]),e._v(" 1.Overview")]),e._v(" "),n("p",[e._v("Supervise training(give the right answer first-training set examples)\nUnsupervise training\nAsymptotes\nSuperscript")]),e._v(" "),n("p",[e._v("Regression problem\nClassification problem")]),e._v(" "),n("h2",{attrs:{id:"_2-linear-regression"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2-linear-regression"}},[e._v("#")]),e._v(" 2.Linear regression")]),e._v(" "),n("p",[e._v("ÊúÄÂ∞è‰∫å‰πòÊ≥ïÔºàleast squares methodÔºâ\nhttps://www.youtube.com/watch?v=MC7l96tW8V8\nÊúÄÂ∞è‰∫å‰πòÊ≥ïÔºàLeast SquareÔºâÂíåÊúÄÂ§ß‰ººÁÑ∂‰º∞ËÆ°\nLeast squares cost function\nÊúÄÂ∞è‰∫å‰πòÊ≥ïÁöÑÊú¨Ë¥®ÊòØ‰ªÄ‰πàÔºü https://www.zhihu.com/question/37031188\nÂú®ËøõË°åÁ∫øÊÄßÂõûÂΩíÊó∂Ôºå‰∏∫‰ªÄ‰πàÊúÄÂ∞è‰∫å‰πòÊ≥ïÊòØÊúÄ‰ºòÊñπÊ≥ï https://www.zhihu.com/question/24095027")]),e._v(" "),n("p",[e._v("‰ªÄ‰πàÊó∂ÂÄôÊúÄÂ∞è‰∫å‰πòÂèÇÊï∞‰º∞ËÆ°ÂíåÊúÄÂ§ß‰ººÁÑ∂‰º∞ËÆ°ÁªìÊûúÁõ∏ÂêåÔºü\nhttps://www.jiqizhixin.com/articles/2018-01-09-6\nÊúÄÂ∞è‰∫å‰πòÊ≥ïÊòØÂè¶‰∏ÄÁßçÂ∏∏Áî®ÁöÑÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÂèÇÊï∞‰º∞ËÆ°ÊñπÊ≥ï„ÄÇÁªìÊûúË°®ÊòéÔºåÂΩìÊ®°ÂûãÂêë‰∏äËø∞‰æãÂ≠ê‰∏≠‰∏ÄÊ†∑Ë¢´ÂÅáËÆæ‰∏∫È´òÊñØÂàÜÂ∏ÉÊó∂ÔºåMLE ÁöÑ‰º∞ËÆ°Á≠â‰ª∑‰∫éÊúÄÂ∞è‰∫å‰πòÊ≥ï„ÄÇ\nÁõ¥Ëßâ‰∏äÔºåÊàë‰ª¨ÂèØ‰ª•ÈÄöËøáÁêÜËß£‰∏§ÁßçÊñπÊ≥ïÁöÑÁõÆÁöÑÊù•Ëß£ÈáäËøô‰∏§ÁßçÊñπÊ≥ï‰πãÈó¥ÁöÑËÅîÁ≥ª„ÄÇÂØπ‰∫éÊúÄÂ∞è‰∫å‰πòÂèÇÊï∞‰º∞ËÆ°ÔºåÊàë‰ª¨ÊÉ≥Ë¶ÅÊâæÂà∞ÊúÄÂ∞èÂåñÊï∞ÊçÆÁÇπÂíåÂõûÂΩíÁ∫ø‰πãÈó¥Ë∑ùÁ¶ªÂπ≥Êñπ‰πãÂíåÁöÑÁõ¥Á∫øÔºàËßÅ‰∏ãÂõæÔºâ„ÄÇÂú®ÊúÄÂ§ß‰ººÁÑ∂‰º∞ËÆ°‰∏≠ÔºåÊàë‰ª¨ÊÉ≥Ë¶ÅÊúÄÂ§ßÂåñÊï∞ÊçÆÂêåÊó∂Âá∫Áé∞ÁöÑÊÄªÊ¶ÇÁéá„ÄÇÂΩìÂæÖÊ±ÇÂàÜÂ∏ÉË¢´ÂÅáËÆæ‰∏∫È´òÊñØÂàÜÂ∏ÉÊó∂ÔºåÊúÄÂ§ßÊ¶ÇÁéá‰ºöÂú®Êï∞ÊçÆÁÇπÊé•ËøëÂπ≥ÂùáÂÄºÊó∂ÊâæÂà∞„ÄÇÁî±‰∫éÈ´òÊñØÂàÜÂ∏ÉÊòØÂØπÁß∞ÁöÑÔºåËøôÁ≠â‰ª∑‰∫éÊúÄÂ∞èÂåñÊï∞ÊçÆÁÇπ‰∏éÂπ≥ÂùáÂÄº‰πãÈó¥ÁöÑË∑ùÁ¶ª„ÄÇ")]),e._v(" "),n("h3",{attrs:{id:"_2-1-univariate-linear-regression-linear-regression-with-one-variable"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-univariate-linear-regression-linear-regression-with-one-variable"}},[e._v("#")]),e._v(" 2.1 Univariate linear regression / Linear regression with one variable")]),e._v(" "),n("p",[e._v("‰∏§ÁßçÊñπÊ≥ïÊ±ÇÁ≥ªÊï∞")]),e._v(" "),n("p",[e._v("1.Áõ¥Êé•Êï∞Â≠¶ÊäÄÂ∑ß")]),e._v(" "),n("p",[e._v("‚àëy = na + b‚àëx")]),e._v(" "),n("p",[e._v("‚àëxy = ‚àëxa + b‚àëx¬≤")]),e._v(" "),n("p",[e._v("=>")]),e._v(" "),n("p",[e._v("b = n‚àëxy ‚Äì (‚àëx)(‚àëy)   n‚àëx¬≤ ‚Äì (‚àëx)¬≤")]),e._v(" "),n("p",[e._v("a = ‚àëy ‚Äì b‚àëx   n")]),e._v(" "),n("p",[e._v("https://www.accountingverse.com/managerial-accounting/cost-behavior/least-squares-method.html")]),e._v(" "),n("p",[e._v("ÂèòÂΩ¢/ÂΩ¢ÂºèÂèòÊç¢\nhttps://blog.csdn.net/u011026329/article/details/79183114")]),e._v(" "),n("p",[n("img",{attrs:{src:"/docs/docs_image/software/bigdata/machinelearning01.png",alt:""}})]),e._v(" "),n("p",[e._v("2.ÊúÄÂ∞è‰∫å‰πòÊ≥ïÊ±ÇÂØº")]),e._v(" "),n("p",[n("img",{attrs:{src:"/docs/docs_image/software/bigdata/machinelearning02.png",alt:""}})]),e._v(" "),n("h3",{attrs:{id:"_2-2-linear-regression-with-multiple-variable"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-linear-regression-with-multiple-variable"}},[e._v("#")]),e._v(" 2.2 Linear regression with multiple variable")]),e._v(" "),n("p",[e._v("Âõ†‰∏∫Á≥ªÊï∞ËøáÂ§öÊó†Ê≥ïÂÉè‰∏äÈù¢Áõ¥Êé•Ê±ÇËß£ÔºåÂè¶Â§ñÂ¶ÇÊûúÁõ¥Êé•Ê±ÇËß£Êó†Ê≥ïÁªßÁª≠Áî®regularlizationÊù•ÊÉ©ÁΩöÁ≥ªÊï∞‰ªéËÄåÊéßÂà∂overfittingÔºåÊâÄ‰ª•Áõ¥Êé•Ê†πÊçÆÊúÄÂ∞è‰∫å‰πòÊ≥ïÊûÑÈÄ†cost function\n"),n("img",{attrs:{src:"/docs/docs_image/software/bigdata/machinelearning03.png",alt:""}})]),e._v(" "),n("p",[e._v("http://www.fanyeong.com/2017/03/29/machine-learning-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%EF%BC%88linear-regression%EF%BC%89/\n‰∏äÈù¢Âõæ‰∏≠ÊèêÂà∞ÁöÑÈô§mÊõ¥Â•ΩÊòØÁî®"),n("s",[e._v("Â§ßÊï∞ÂÆöÁêÜ")]),e._v("‰∏≠ÂøÉÊûÅÈôêÂÆöÁêÜÊù•Ëß£ÈáäÔºåÂç≥ÂΩìÊ†∑Êú¨Ë∂≥Â§üÂ§ßÔºåÂùáÂÄºÁ≠â‰∫éÊï∞Â≠¶ÊúüÊúõÔºàÁÆóÊúØÂπ≥ÂùáÂÄºÔºâÔºåÊ≠§Â§ÑÂç≥ËØØÂ∑ÆÁöÑÂùáÂÄºÁ≠â‰∫éÊï∞Â≠¶ÊúüÊúõ\n"),n("img",{attrs:{src:"/docs/docs_image/software/bigdata/machinelearning04.png",alt:""}}),e._v("\nhttps://stats.stackexchange.com/questions/155580/cost-function-in-ols-linear-regression")]),e._v(" "),n("p",[e._v("Ê¢ØÂ∫¶‰∏ãÈôç\n"),n("img",{attrs:{src:"/docs/docs_image/software/bigdata/machinelearning05.png",alt:""}})]),e._v(" "),n("h2",{attrs:{id:"_3-logistic-regression"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-logistic-regression"}},[e._v("#")]),e._v(" 3. Logistic regression")]),e._v(" "),n("p",[e._v("Sigmoid function / logistic function\n‰∏∫‰ªÄ‰πàÈááÁî®sigmoid functionÔºàÊ≠£ÊÄÅÂàÜÂ∏ÉÔºâ‰Ωú‰∏∫cost function\nË∑ü ÊúÄÂ§ß‰ººÁÑ∂‰º∞ËÆ°ÊúâÂÖ≥\nhttp://www.hanlongfei.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2015/08/05/mle/")]),e._v(" "),n("p",[n("img",{attrs:{src:"/docs/docs_image/software/bigdata/machinelearning06.png",alt:""}})]),e._v(" "),n("p",[e._v("regularization\n"),n("img",{attrs:{src:"/docs/docs_image/software/bigdata/machinelearning07.png",alt:""}})]),e._v(" "),n("h2",{attrs:{id:"quiz"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#quiz"}},[e._v("#")]),e._v(" Quiz")]),e._v(" "),n("p",[e._v("Linear Regression with One Variable")]),e._v(" "),n("ol",[n("li",[n("p",[e._v('Consider the problem of predicting how well a student does in her second year of college/university, given how well she did in her first year.\nSpecifically, let x be equal to the number of "A" grades (including A-. A and A+ grades) that a student receives in their first year of college (freshmen year). We would like to predict the value of y, which we define as the number of "A" grades they get in their second year (sophomore year).\nHere each row is one training example. Recall that in linear regression, our hypothesis is hŒ∏(x)=Œ∏0+Œ∏1x, and we use m to denote the number of training examples.\n| x | y |\n|---|---|\n| 5 | 4 |\n| 3 | 4 |\n| 0 | 1 |\n| 4 | 3 |\nFor the training set given above (note that this training set may also be referenced in other questions in this quiz), what is the value of m? In the box below, please enter your answer (which should be a number between 0 and 10).')])]),e._v(" "),n("li",[n("p",[e._v("For this question, assume that we are\nusing the training set from Q1. Recall our definition of the\ncost function was J(Œ∏0,Œ∏1)=12m‚àëmi=1(hŒ∏(x(i))‚àíy(i))2.\nWhat is J(0,1)? In the box below,\nplease enter your answer (Simplify fractions to decimals when entering answer, and '.' as the decimal delimiter e.g., 1.5).")])]),e._v(" "),n("li",[n("p",[e._v("Suppose we set Œ∏0=‚àí1,Œ∏1=2 in the linear regression hypothesis from Q1. What is hŒ∏(6)?")])]),e._v(" "),n("li",[n("p",[e._v("Let f be some function so that\nf(Œ∏0,Œ∏1) outputs a number. For this problem,\nf is some arbitrary/unknown smooth function (not necessarily the\ncost function of linear regression, so f may have local optima).\nSuppose we use gradient descent to try to minimize f(Œ∏0,Œ∏1)\nas a function of Œ∏0 and Œ∏1. Which of the\nfollowing statements are true? (Check all that apply.)\nIf Œ∏0 and Œ∏1 are initialized so that Œ∏0=Œ∏1, then by symmetry (because we do simultaneous updates to the two parameters), after one iteration of gradient descent, we will still have Œ∏0=Œ∏1.\nIf the learning rate is too small, then gradient descent may take a very long\ntime to converge.\nIf Œ∏0 and Œ∏1 are initialized at\na local minimum, then one iteration will not change their values.\nEven if the learning rate Œ± is very large, every iteration of\ngradient descent will decrease the value of f(Œ∏0,Œ∏1).")])]),e._v(" "),n("li",[n("p",[e._v("Suppose that for some linear regression problem (say, predicting housing prices as in the lecture), we have some training set, and for our training set we managed to find some Œ∏0, Œ∏1 such that J(Œ∏0,Œ∏1)=0.\nWhich of the statements below must then be true? (Check all that apply.)\nOur training set can be fit perfectly by a straight line,\ni.e., all of our training examples lie perfectly on some straight line.\nFor this to be true, we must have y(i)=0 for every value of i=1,2,‚Ä¶,m.\nFor this to be true, we must have Œ∏0=0 and Œ∏1=0\nso that hŒ∏(x)=0\nGradient descent is likely to get stuck at a local minimum and fail to find the global minimum.")])]),e._v(" "),n("li",[n("p",[e._v("Many substances that can burn (such as gasoline and alcohol) have a chemical structure based on carbon atoms; for this reason they are called hydrocarbons. A chemist wants to understand how the number of carbon atoms in a molecule affects how much energy is released when that molecule combusts (meaning that it is burned). The chemist obtains the dataset below. In the column on the right, ‚ÄúkJ/mol‚Äù is the unit measuring the amount of energy released.\n| Name of molecule | Number of hydrocarbons in molecule(x) | Heat release when burned(kJ/mol)(y)|\n|---|---|---|\n| methane | 1 | -890 |\n| ethene | 2 | -1411 |\n| ethane | 2 | -1560 |\n| propane | 3 | -2220 |\n| cyclopropane | 3 | -2091 |\n| butane | 4 | -2878 |\n| pentane | 5 | -3537 |\n| benzene | 6 | -3268 |\n| cycloexane | 6 | -3920 |\n| hexane | 6 | -4163 |\n| octane | 8 | -5471 |\n| napthalene | 10 | -5157 |")])])]),e._v(" "),n("p",[e._v("You would like to use linear regression (hŒ∏(x)=Œ∏0+Œ∏1x) to estimate the amount of energy released (y) as a function of the number of carbon atoms (x). Which of the following do you think will be the values you obtain for Œ∏0 and Œ∏1? You should be able to select the right answer without actually implementing linear regression.")]),e._v(" "),n("p",[e._v("Linear Regression with Multiple Variables")]),e._v(" "),n("ol",[n("li",[e._v("Suppose m=4 students have taken some class, and the class had a midterm exam and a final exam. You have collected a dataset of their scores on the two exams, which is as follows:")])]),e._v(" "),n("table",[n("thead",[n("tr",[n("th",[e._v("midterm exam")]),e._v(" "),n("th",[e._v("(midterm exam)2")]),e._v(" "),n("th",[e._v("final exam")])])]),e._v(" "),n("tbody",[n("tr",[n("td",[e._v("89")]),e._v(" "),n("td",[e._v("7921")]),e._v(" "),n("td",[e._v("96")])]),e._v(" "),n("tr",[n("td",[e._v("72")]),e._v(" "),n("td",[e._v("5184")]),e._v(" "),n("td",[e._v("74")])]),e._v(" "),n("tr",[n("td",[e._v("94")]),e._v(" "),n("td",[e._v("8836")]),e._v(" "),n("td",[e._v("87")])]),e._v(" "),n("tr",[n("td",[e._v("69")]),e._v(" "),n("td",[e._v("4761")]),e._v(" "),n("td",[e._v("78")])])])]),e._v(" "),n("p",[e._v("You'd like to use polynomial regression to predict a student's final exam score from their midterm exam score. Concretely, suppose you want to fit a model of the form hŒ∏(x)=Œ∏0+Œ∏1x1+Œ∏2x2, where x1 is the midterm score and x2 is (midterm score)2. Further, you plan to use both feature scaling (dividing by the \"max-min\", or range, of a feature) and mean normalization.What is the normalized feature x(3)1? (Hint: midterm = 94, final = 87 is training example 3.) Please round off your answer to two decimal places and enter in the text box below.")]),e._v(" "),n("ol",{attrs:{start:"2"}},[n("li",[n("p",[e._v("You run gradient descent for 15 iterationsÔºåwith Œ±=0.3 and compute,J(Œ∏) after each iteration. You find that the value of J(Œ∏) decreases slowly and is still decreasing after 15 iterations. Based on this, which of the following conclusions seems most plausible? Rather than use the current value of Œ±, it'd be more promising to try a smaller value of Œ± (say Œ±=0.1). Œ±=0.3 is an effective choice of learning rate.Rather than use the current value of Œ±, it'd be more promising to try a larger value of Œ± (say Œ±=1.0).")])]),e._v(" "),n("li",[n("p",[e._v("Suppose you have m=23 training examples with n=5 features (excluding the additional all-ones feature for the intercept term, which you should add). The normal equation is Œ∏=(XTX)‚àí1XTy. For the given values of m and n, what are the dimensions of Œ∏, X, and y in this equation?\nX is 23√ó6, y is 23√ó6, Œ∏ is 6√ó6\nX is 23√ó5, y is 23√ó1, Œ∏ is 5√ó1\nX is 23√ó6, y is 23√ó1, Œ∏ is 6√ó1\nX is 23√ó5, y is 23√ó1, Œ∏ is 5√ó5")])]),e._v(" "),n("li",[n("p",[e._v("Suppose you have a dataset with m=50 examples and n=15 features for each example. You want to use multivariate linear regression to fit the parameters Œ∏ to our data. Should you prefer gradient descent or the normal equation? Gradient descent, since it will always converge to the optimal Œ∏. The normal equation, since it provides an efficient way to directly find the solution. Gradient descent, since (XTX)‚àí1 will be very slow to compute in the normal equation. The normal equation, since gradient descent might be unable to find the optimal Œ∏.")])]),e._v(" "),n("li",[n("p",[e._v("Which of the following are reasons for using feature scaling?\nIt speeds up gradient descent by making each iteration of gradient descent less expensive to compute.\nIt speeds up gradient descent by making it require fewer iterations to get to a good solution.\nIt prevents the matrix XTX (used in the normal equation) from being non-invertable (singular/degenerate).\nIt is necessary to prevent the normal equation from getting stuck in local optima.")])])]),e._v(" "),n("p",[e._v("Êú∫Âô®Â≠¶‰π†ÈîôÈ¢òÈõÜ")]),e._v(" "),n("ol",[n("li",[n("p",[e._v("Some of the problems below are best addressed using a supervised learning algorithm, and the others with an unsupervised learning algorithm. Which of the following would you apply supervised learning to? (Select all that apply.) In each case,assume some appropriate dataset is available for your algorithm to learn from. „ÄêA,C„Äë\nA. Given historical data of childrens' ages and heights, predict children's height as a function of their age.\n„ÄêËß£Êûê„ÄëThis is a supervised learning, regression problem, where we can learn from a training set to predict height.\nB.  Examine a large collection of emails that are known to be spam email, to discover if there are sub-types of spam mail.\n„ÄêËß£Êûê„ÄëThis can addressed using a clustering (unsupervised learning) algorithm, to cluster spam mail into sub-types.\nC.  Examine the statistics of two football teams, and predicting which team will win tomorrow's match (given historical data of teams' wins/losses to learn from).\n„ÄêËß£Êûê„ÄëThis can be addressed using supervised learning, in which we learn from historical records to make win/loss predictions.\nD.  Given a large dataset of medical records from patients suffering from heart disease, try to learn whether there might be different clusters of such patients for which we might tailor separate treatements.\n„ÄêËß£Êûê„ÄëThis can be addressed using an unsupervised learning, clustering, algorithm, in which we group patients into different clusters.")])]),e._v(" "),n("li",[n("p",[e._v('Suppose that for some linear regression problem (say, predicting housing prices as in the lecture), we have some training set, and for our training set we managed to find some Œ∏0, Œ∏1 such that J(Œ∏0,Œ∏1)=0. Which of the statements below must then be true?  „ÄêA„Äë\nA. For these values of Œ∏0 and Œ∏1 that satisfy J(Œ∏0,Œ∏1)=0, we have that hŒ∏(x(i))=y(i) for every training example (x(i),y(i))\n„ÄêËß£Êûê„ÄëJ(Œ∏0,Œ∏1)=0, that means the line defined by the equation "y=Œ∏0+Œ∏1x" perfectly fits all of our data.\nB. For this to be true, we must have y(i)=0 for every value of i=1,2,‚Ä¶,m.\n„ÄêËß£Êûê„ÄëSo long as all of our training examples lie on a straight line, we will be able to find Œ∏0 and Œ∏1 so that J(Œ∏0,Œ∏1)=0. It is not necessary that y(i)=0 for all of our examples.\nC. Gradient descent is likely to get stuck at a local minimum and fail to find the global minimum.\n„ÄêËß£Êûê„ÄëThe cost function J(Œ∏0,Œ∏1) for linear regression has no local optima (other than the global minimum), so gradient descent will not get stuck at a bad local minimum.\nD.We can perfectly predict the value of y even for new examples that we have not yet seen. (e.g., we can perfectly predict prices of even new houses that we have not yet seen.)\n„ÄêËß£Êûê„ÄëEven though we can fit our training set perfectly, this does not mean that we\'ll always make perfect predictions on houses in the future/on houses that we have not yet seen.')])]),e._v(" "),n("li",[n("p",[e._v("Which of the following are reasons for using feature scaling?\nIt speeds up gradient descent by making it require fewer iterations to get to a good solution.\n„ÄêËß£Êûê„ÄëFeature scaling speeds up gradient descent by avoiding many extra iterations that are required when one or more features take on much larger values than the rest.\nThe cost function J(Œ∏) for linear regression has no local optima.\nThe magnitude of the feature values are insignificant in terms of computational cost.")])]),e._v(" "),n("li",[n("p",[e._v("You run gradient descent for 15 iterations with Œ±=0.3 and compute J(Œ∏) aftereach iteration. You find that the value of J(Œ∏) decreases quickly then levels off. Based on this, which of the following conclusions seems most plausible?\nA smaller learning rate will only decrease the rate of convergence to the cost function's minimum, thus increasing the number of iterations needed.")])]),e._v(" "),n("li",[n("p",[e._v("You are training a classification model with logistic regression. Which of the following statements are true? Check all that apply.„ÄêD„Äë\nA. Introducing regularization to the model always results in equal or better performance on the training set.\n„ÄêËß£Êûê„ÄëIf we introduce too much regularization, we can underfit the training set and have worse performance on the training set.\nB.Adding many new features to the model helps prevent overfitting on the training set.\n„ÄêËß£Êûê„ÄëAdding many new features gives us more expressive models which are able to better fit our training set. If too many new features are added, this can lead to overfitting of the training set.\nC. Adding a new feature to the model always results in equal or better performance on examples not in the training set.\n„ÄêËß£Êûê„ÄëAdding  more features might result in a model that overfits the training set, and thus can lead to worse performs for examples which are not in the training set.\nD.Adding a new feature to the model always results in equal or better performance on the training set.\n„ÄêËß£Êûê„ÄëBy adding a new feature, our model must be more (or just as) expressive, thus allowing it learn more complex hypotheses to fit the training set.")])]),e._v(" "),n("li",[n("p",[e._v('Which of the following statements about regularization are true? Check all that apply.„ÄêD„Äë\nA.Because regularization causes J(Œ∏) to no longer be convex, gradient descent may not always converge to the global minimum (when Œª>0, and when using an appropriate learning rate Œ±).\n„ÄêËß£Êûê„ÄëRegularized logistic regression and regularized linear regression are both convex, and thus gradient descent will still converge to the global minimum.\nB.Using too large a value of Œª can cause your hypothesis to overfit the data; this can be avoided by reducing Œª.\n„ÄêËß£Êûê„ÄëUsing a very large value of Œª can lead to underfitting of the training set.\nC.Because logistic regression outputs values 0‚â§hŒ∏(x)‚â§1, it\'s range of output values can only be "shrunk" slightly by regularization anyway, so regularization is generally not helpful for it.\n„ÄêËß£Êûê„ÄëRegularization affects the parameters Œ∏ and is also helpful for logistic regression.\nD.Consider a classification problem. Adding regularization may cause your classifier to incorrectly classify some training examples (which it had correctly classified when not using regularization, i.e. when Œª=0).\n„ÄêËß£Êûê„ÄëRegularization penalizes complex models (with large values of Œ∏).They can lead to a simpler models, which misclassifies more training examples.')])]),e._v(" "),n("li",[n("p",[e._v("Which of the following statements about regularization are true? Check all that apply.„ÄêA,B,C,D„Äë\nA.For computational efficiency, after we have performed gradient checking to verify that our backpropagation code is correct, we usually disable gradient checking before using backpropagation to train the network.\n„ÄêËß£Êûê„ÄëChecking the gradient numerically is a debugging tool: it helps ensure a correct implementation,\nbut it is too slow to use as a method for actually computing gradients.\nB.If our neural network overfits the training set, one reasonable step to take is to increase the regularization parameter Œª.\n„ÄêËß£Êûê„ÄëJust as with logistic regression, a large value of Œª will penalize large parameter values, thereby reducing the changes of overfitting the training set.\nC.Suppose you are training a neural network using gradient descent. Depending on your random initialization, your algorithm may converge to different local optima (i.e., if you run the algorithm twice with different random initializations, gradient descent may converge to two different solutions).\n„ÄêËß£Êûê„ÄëThe cost function for a neural network is non-convex, so it may have multiple minima. Which minimum you find with gradient descent depends on the initialization.\nD.Suppose we have a correct implementation of backpropagation, and are training a neural network using gradient descent. Suppose we plot J(Œò) as a function of the number of iterations, and find that it is increasing rather than decreasing. One possible cause of this is that the learning rate Œ± is too large.\n„ÄêËß£Êûê„ÄëIf the learning rate is too large, the cost function can diverge during gradient descent. Thus, you should select a smaller value of Œ±.\nE.Suppose that the parameter Œò(1) is a square matrix (meaning the number of rows equals the number of columns). If we replace Œò(1) with its transpose (Œò(1))T, then we have not changed the function that the network is computing.\n„ÄêËß£Êûê„ÄëŒò(1) can be an arbitrary matrix, so when you compute a(2)=g(Œò(1)a(1)), replacing Œò(1) with its transpose will compute a different value.\nF.Suppose we are using gradient descent with learning rate Œ±. For logistic regression and linear regression, J(Œ∏) was a convex optimization problem and thus we did not want to choose a learning rate Œ± that is too large. For a neural network however, J(Œò) may not be convex, and thus choosing a very large value of Œ± can only speed up convergence.\n„ÄêËß£Êûê„ÄëEven when J(Œò) is not convex, a learning rate that is too large can prevent gradient descent from converging.\nG.Using a large value of Œª cannot hurt the performance of your neural network; the only reason we do not set Œª to be too large is to avoid numerical problems.\n„ÄêËß£Êûê„ÄëA large value of Œª can be quite detrimental. If you set it too high, then the network will be underfit to the training data and give poor predictions on both training data and new, unseen test data.\nH.Gradient checking is useful if we are using gradient descent as our optimization algorithm. However, it serves little purpose if we are using one of the advanced optimization methods (such as in fminunc).\n„ÄêËß£Êûê„ÄëGradient checking will still be useful with advanced optimization methods, as they depend on computing the gradient at given parameter settings. The difference is they use the gradient values in more sophisticated ways than gradient descent.")])])]),e._v(" "),n("p",[e._v("exercise")]),e._v(" "),n("p",[e._v("This post contains links to all of the programming exercise tutorials.\nAfter clicking on a link, you may need to scroll down to find the highlighted post.\n--- Note: Additional test cases can be found"),n("a",{attrs:{href:"https://www.coursera.org/learn/machine-learning/discussions/0SxufTSrEeWPACIACw4G5w",target:"_blank",rel:"noopener noreferrer"}},[e._v("here"),n("OutboundLink")],1)]),e._v(" "),n("p",[e._v("ex1\ncomputeCost() tutorial - also applies to computeCostMulti().\ngradientDescent() - also applies to gradientDescentMulti() - includes test cases.\nfeatureNormalize() tutorial\nNote: if you use OS X and the contour plot doesn't display correctly, see the Course Wiki for additional tips.")]),e._v(" "),n("hr"),e._v(" "),n("p",[e._v("ex1 Tutorial for computeCost\nTom MosherMentorWeek 2 ¬∑ 2 years ago ¬∑ Edited\nThis is a step-by-step tutorial for how to complete the computeCost() function portion of ex1. You will still have to do some thinking, because I'll describe the implementation, but you have to turn it into Octave script commands.\nAll the programming exercises in this course follow the same procedure; you are provided a starter code template for a function that you need to complete. You never have to start a new script file from scratch.\nThis is a vectorized implementation. You're only going to write a few simple lines of code.\nWith a text editor (NOT a word processor), open up the computeCost.m file. Scroll down until you find the \"====== YOUR CODE HERE =====\" section. Below this section is where you're going to add your lines of code. Just skip over the lines that start with the '%' sign - those are instructive comments.\nWe'll write these three lines of code by inspecting the equation on Page 5 of ex1.pdf\nThe first line of code will compute a vector 'h' containing all of the hypothesis values - one for each training example (i.e. for each row of X).\nThe hypothesis (also called the prediction) is simply the product of X and theta. So your first line of code is‚Ä¶\nh = {multiply X and theta, in the proper order that the inner    dimensions match}\nSince X is size (m x n) and theta is size (n x 1), you arrange the order of operators so the result is size (m x 1).\nThe second line of code will compute the difference between the hypothesis and y - that's the error for each training example. Difference means subtract.\nerror = {the difference between h and y}\nThe third line of code will compute the square of each of those error terms (using element-wise exponentiation),\nAn example of using element-wise exponentiation - try this in your workspace command line so you see how it works.\nv = [-2 3]\nv_sqr = v.^2\nSo, now you should compute the squares of the error terms:\nerror_sqr = {use what you have learned}\nNext, here's an example of how the sum function works (try this from your command line)\nq = sum([1 2 3])\nNow, we'll finish the last two steps all in one line of code. You need to compute the sum of the error_sqr vector, and scale the result (multiply) by 1/(2"),n("em",[e._v("m). That completed sum is the cost value J.\nJ = {multiply 1/(2")]),e._v('m) times the sum of the error_sqr vector}\nThat\'s it. If you run the ex1.m script (by entering the command "ex1" in the console), you should have the correct value for J. Then you should test further by running the additional Test Cases (available via the Resources menu).\nImportant Note: You cannot test your computeCost() function by simply entering "computeCost" or "computeCost()" in the console. The function requires that you pass it three data parameters (X, y, and theta). The "ex1" script does this for you.\nThen you can run the "submit" script, and hopefully it will pass.\nNote: Be sure that every line of code ends with a semicolon. That will suppress the output of any values to the workspace. Leaving out the semicolons will surely make the grader unhappy.')]),e._v(" "),n("p",[e._v("============")]),e._v(" "),n("p",[e._v("ex2\nNote: If you are using MATLAB version R2015a or later, the fminunc() function has been changed in this version. The function works better, but does not give the expected result for Figure 5 in ex2.pdf, and it throws some warning messages (about a local minimum) when you run ex2_reg.m. This is normal, and you should still be able to submit your work to the grader.\nNote: If your installation has trouble with the GradObj option, see this thread: "),n("link"),e._v('\nNote: If you are using a linux-derived operating system, you may need to remove the attribute "MarkerFaceColor" from the plot() function call in plotData.m.')]),e._v(" "),n("hr"),e._v(" "),n("p",[e._v("sigmoid() tutorial\ncostFunction() cost tutorial - also good for costFunctionReg()\ncostFunction() gradient tutorial - also good for costFunctionReg()\npredict() - tutorial for logistic regression prediction\nDiscussion of plotDecisionBoundary() "),n("link")]),e._v(" "),n("hr"),e._v(" "),n("p",[e._v('ex3\nNote: a change to displayData.m for MacOS users: (link)\nNote: if your images are upside-down, use flipud() to reverse the data. This is due to a change in gnuplot()\'s defaults.\nlrCostFunction() - This function is identical to your costFunctionReg() from ex2. Do not remove the line "grad = grad(üòÉ" from the end of the lrCostFunction.m script template. This line guarantees that the grad value is returned as a column vector.\noneVsAll() tutorial\npredictOneVsAll() tutorial (updated)\npredict() tutorial (for the NN forward propagation - updated)')]),e._v(" "),n("hr"),e._v(" "),n("p",[e._v("ex4\nnnCostFunction() - forward propagation and cost w/ regularization\nnnCostFunction() - tutorial for backpropagation\nTutorial on using matrix multiplication to compute the cost value 'J'")]),e._v(" "),n("hr"),e._v(" "),n("p",[e._v("ex5\nlinearRegCostFunction() tutorial\npolyFeatures() - tutorial\nlearningCurve() tutorial (really just a set of tips)\nvalidationCurve() tips")]),e._v(" "),n("hr"),e._v(" "),n("p",[e._v('ex6\nNote: Update to ex6.m: At line 69/70, change "sigma = 0.5" to "sigma = %0.5f"\nand change the list of output variables from "sim" to "sigma, sim".\n(note: As of Jan 2017, this issue is already included in the zip file)\nNote: Error in visualizeBoundary.m. Change the call to contour() like this:\ncontour(X1, X2, vals, [1 1], \'b\');\n(This change removes the attribute \'Color\', and changes the contour interval. Note that [0.5 0.5] also works and is more logical, since "vals" has range [0..1])\nThis issue can cause either the "hggroup" error message, or the decision boundaries to not be displayed, or possibly cause Octave 3.8.x to crash when running ex6.m.\nAll ex6 tutorials (link)')]),e._v(" "),n("hr"),e._v(" "),n("p",[e._v("ex7\nfindClosestCentroids() tutorial\ncomputeCentroids() tutorial\nTutorials for ex7_pca functions - pca(), projectData(), recoverData()")]),e._v(" "),n("hr"),e._v(" "),n("p",[e._v('ex8\nselectThreshold() - use the tips in the function script template, and the bulleted list on page 6 of ex8.pdf, to compute each of the tp, fp, and fn values.\nNote: error in ex8_cofi.m (click this link)\nTip for estimateGaussian(): Compute the mean using "mean()". You can compute sigma2 using the equation in ex8.pdf, or you can use "var()" if you set the OPT parameter so it normalizes over the entire sample size.\ncofiCostFunc() tutorial')]),e._v(" "),n("p",[e._v("--")]),e._v(" "),n("p",[e._v("ref:")]),e._v(" "),n("p",[e._v("Coursera\nhttps://www.coursera.org/learn/machine-learning/home/welcome")]),e._v(" "),n("p",[e._v("MIT\nArtificial Intelligence https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/")]),e._v(" "),n("p",[e._v("Coursera‰∏äÊú∫Âô®Â≠¶‰π†ËØæÁ®ãÔºàÂÖ¨ÂºÄËØæÔºâÊ±áÊÄªÊé®Ëçê\nhttp://blog.coursegraph.com/tag/Êú∫Âô®Â≠¶‰π†\nÊñØÂù¶Á¶èÊú∫Âô®Â≠¶‰π†Á¨îËÆ∞ https://legacy.gitbook.com/book/yoyoyohamapi/mit-ml/details\nhttp://openclassroom.stanford.edu/MainFolder/DocumentPage.php?course=MachineLearning&doc=exercises/ex7/ex7.html")])])}),[],!1,null,null,null);t.default=i.exports}}]);