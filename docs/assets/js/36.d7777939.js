(window.webpackJsonp=window.webpackJsonp||[]).push([[36],{240:function(e,a,t){"use strict";t.r(a);var s=t(0),o=Object(s.a)({},(function(){var e=this,a=e.$createElement,t=e._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("p",[t("img",{attrs:{src:"/docs/docs_image/software/kafka/kafka01.png",alt:""}}),e._v(" "),t("img",{attrs:{src:"/docs/docs_image/software/kafka/kafka02.png",alt:""}}),e._v(" "),t("img",{attrs:{src:"/docs/docs_image/software/kafka/kafka03.png",alt:""}}),e._v(" "),t("img",{attrs:{src:"/docs/docs_image/software/kafka/kafka04.png",alt:""}}),e._v(" "),t("img",{attrs:{src:"/docs/docs_image/software/kafka/kafka05.png",alt:""}})]),e._v(" "),t("p",[e._v("1.Basic Concepts\nWhat’s Kafka\nWhy use Kafka\nHow it works\n2.Exactly once Semantics")]),e._v(" "),t("p",[e._v("What’s Kafka")]),e._v(" "),t("p",[e._v("Apache Kafka is a community distributed streaming platform capable of handling trillions of events a day.\nInitially conceived as a messaging queue, Kafka is based on an abstraction of a distributed commit log.\nSince being created and open sourced by LinkedIn in 2011,\nKafka has quickly evolved from messaging queue to a full-fledged event streaming platform.")]),e._v(" "),t("p",[e._v("Why use Kafka")]),e._v(" "),t("p",[e._v("Microservice and kafka already became a de-facto industry standard")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("1.\nbasicaly kafka is a messaging system, compare to other messaging middleware like the one I used before called rabbit mq, with rabbit mq you can only process once,\nafter consuming the message, it's removed from the queue.\nkafka provides durable storage of messages, sometimes kafka is used as a kind of database.\nand now kafka has evolved from messaging queue to full-fleged event streaming platform, we're not using the streaming feature, so today the topic only cover messaging queue.\n\n2.\nwhy do we use kafka\nLet's have a look at architecuture diagram next slides microservices approach vs traditional approach, \nin traditional approach, application stack multiple layers and compononets together as a single unit.\nwe can see microservice segregates functionalities into a set of autonamous services,so the circle connecting microservices is message queue system.\nthere are some advantages for microservice approach,\nthere is no single point of failure, one service broke down doesn't impact other services;\nits easier to scale up, all these services are deployed independently, esier to identify the bottle neck and scale up;\nfrom developer standpoint, it can save a lot of time troubleshooting the microservices compared to debug into the traditional application,\nmicorservice is designed based on single reponsiblity principle, you can find the paticular service responsible for the cause straightforward.\n\n3.\nkafka works like this:\nproducers publish message to the topics on brokers, the consumers subscribe to the topic will continously poll from the brokers.\nin the middle is the brokers, we have 4 brokers, each broker represents one instance of the kafka server, we have 2 topics allocated on the brokers:\ntopic 1 and topic 2, topic 1 have 2 paritions, topic 2 have 1 parition, each topic has two replications, to publish a message, the producers has to specify 3 params:\nthe topic name, which partition and the message itself, the messsage will be published on to leader partition, and the followers will replicate from leader,\n\nconsumers can join in the same group by config the same application id,\neach one partition can be consumed by consumers from different consumer group, but one partition can only be consumed by one consumer in the same consumer group, \nin another word, consumers in the same consumer group load balance the topic partitions, consumers from different consumer group are idenpendent from each other.\n\n4.\none critical concerns is how do we achieve exactly once semantics, how do we guarantee there is no missing or duplicated messages, there is a misconception that \ndevelop using kafka API will inherently has the capbility to achieve exactly once senmantics, truth is we have to design properly.\nto discuss this concern, let's look at a typical application.\nwe post a message to APP-1, APP-1 extract the data,transform and produce the message to kafka, APP-2 will consume the message.\nvery simple but it can go wrong from many aspects.\nfirst, the http call, when we make a http post, it may happen that APP-1 recevied the post data and processed, \nbut somehow failed to return the reposonse back to the http client due to may be network issue, so the http client side will be timeout, \nnormally the http client library will retry for this secnario, if the network recovered, APP-1 will recevie duplicated message, \nin this case from my own experience, what we would do is that we use redis on APP-1 to check duplication. \nthe same may happen when APP-1 publish message to kafka, good news is that in the latest kafka version, \nit already help us handled this secnario, all we need to do is simply config enable idempotence to be ture.\ngo on the consumer side, unfortunately, consumer side is too much complicated, there is no easy way to solve it, \nbefore further discuss, let me clarify the verb 'processing', there are mainly two types of processing: in-memory processing, the other type is data persist(for example \nstore into database, write to kafka), if it's purly in-memory processing there is nothing to worry about, whenever it's broken, so I'm talking about type 2,\n, let's assume processing here means write to kafka.\nTransactional delivery allows producers to send data to multiple partitions such that either all messages are successfully delivered, or none of them are.\n")])])])])}),[],!1,null,null,null);a.default=o.exports}}]);