(window.webpackJsonp=window.webpackJsonp||[]).push([[227],{658:function(t,e,i){"use strict";i.r(e);var n=i(65),s=Object(n.a)({},(function(){var t=this.$createElement,e=this._self._c||t;return e("ContentSlotsDistributor",{attrs:{"slot-key":this.$parent.slotKey}},[e("p",[this._v("While Ollama excels in simplicity, vLLM stands out for its efficient memory management, continuous batching capabilities, and tensor parallelism. This makes it particularly attractive for production environments and high-throughput scenarios.")]),this._v(" "),e("p",[e("a",{attrs:{href:"https://docs.vllm.ai/en/latest/getting_started/quickstart.html",target:"_blank",rel:"noopener noreferrer"}},[this._v("Quickstart"),e("OutboundLink")],1)])])}),[],!1,null,null,null);e.default=s.exports}}]);