(window.webpackJsonp=window.webpackJsonp||[]).push([[180],{609:function(e,a,t){"use strict";t.r(a);var l=t(65),r=Object(l.a)({},(function(){var e=this,a=e.$createElement,t=e._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("p",[e._v("Ollama is an open-source project that serves as a powerful and user-friendly platform for running LLMs on your local machine.")]),e._v(" "),t("p",[e._v("https://ollama.com/")]),e._v(" "),t("p",[e._v("chat mode\nserver mode")]),e._v(" "),t("h2",{attrs:{id:"ollama"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#ollama"}},[e._v("#")]),e._v(" Ollama")]),e._v(" "),t("p",[e._v("user env:")]),e._v(" "),t("ul",[t("li",[e._v("OLLAMA_MODELS")]),e._v(" "),t("li",[e._v("OLLAMA_HOST 0.0.0.0")]),e._v(" "),t("li",[e._v("OLLAMA_ORIGIN *")])]),e._v(" "),t("p",[e._v("Note: 如果系统变量不行，改成用户变量，Ollama prioritizes user environment variables over system ones when loading model paths; meaning the system-wide setting is being ignored unless explicitly configured otherwise.")]),e._v(" "),t("p",[e._v("Port: 11434")]),e._v(" "),t("p",[e._v("Log path: \\Users\\meesi\\AppData\\Local\\Ollama\\Server.log")]),e._v(" "),t("p",[e._v("Models:")]),e._v(" "),t("ul",[t("li",[e._v("Deepseek\n"),t("ul",[t("li",[t("a",{attrs:{href:"https://ollama.com/huihui_ai/deepseek-r1-abliterated",target:"_blank",rel:"noopener noreferrer"}},[e._v("越狱版huihui_ai/deepseek-r1-abliterated"),t("OutboundLink")],1),e._v(" "),t("code",[e._v("ollama run huihui_ai/deepseek-r1-abliterated")])])])]),e._v(" "),t("li",[e._v("other")])]),e._v(" "),t("h2",{attrs:{id:"ollama-anythingllm"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#ollama-anythingllm"}},[e._v("#")]),e._v(" ollama+ AnythingLLM")]),e._v(" "),t("p",[e._v("0基础！一行代码部署Gemma！纯本地！主打一个快！不用搞依赖！7B尺寸超13B性能！附模型下载！\nhttps://mp.weixin.qq.com/s/4hjewv3TFI5fqe66PaT6Tg")])])}),[],!1,null,null,null);a.default=r.exports}}]);