<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>计算机基础教程</title>
    <meta name="generator" content="VuePress 1.9.7">
    <script async="true" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9742852210287449" crossorigin="anonymous"></script>
    <script>
			(function() { // DON'T EDIT BELOW THIS LINE
			
			})();
		 </script>
    <meta name="description" content="软件开发教程，白帽黑客入门教程，区块链入门教程，物联网，大数据">
    
    <link rel="preload" href="/docs/assets/css/0.styles.4f35daf1.css" as="style"><link rel="preload" href="/docs/assets/js/app.ecfc7657.js" as="script"><link rel="preload" href="/docs/assets/js/2.37e66b58.js" as="script"><link rel="preload" href="/docs/assets/js/97.ec193d7a.js" as="script"><link rel="prefetch" href="/docs/assets/js/10.d81249de.js"><link rel="prefetch" href="/docs/assets/js/100.863c1f7d.js"><link rel="prefetch" href="/docs/assets/js/101.98763536.js"><link rel="prefetch" href="/docs/assets/js/102.7990488c.js"><link rel="prefetch" href="/docs/assets/js/103.9e38ac6f.js"><link rel="prefetch" href="/docs/assets/js/104.a508c82c.js"><link rel="prefetch" href="/docs/assets/js/105.b87e616c.js"><link rel="prefetch" href="/docs/assets/js/106.f06a7dcc.js"><link rel="prefetch" href="/docs/assets/js/107.dad500da.js"><link rel="prefetch" href="/docs/assets/js/108.56fd7f41.js"><link rel="prefetch" href="/docs/assets/js/109.7bbd8b45.js"><link rel="prefetch" href="/docs/assets/js/11.f6e7f18e.js"><link rel="prefetch" href="/docs/assets/js/110.bff52715.js"><link rel="prefetch" href="/docs/assets/js/111.8464dc4c.js"><link rel="prefetch" href="/docs/assets/js/112.5589d6bd.js"><link rel="prefetch" href="/docs/assets/js/113.24d32b93.js"><link rel="prefetch" href="/docs/assets/js/114.1c2ce534.js"><link rel="prefetch" href="/docs/assets/js/115.149a18de.js"><link rel="prefetch" href="/docs/assets/js/116.7bc0286a.js"><link rel="prefetch" href="/docs/assets/js/117.d1ad4a2b.js"><link rel="prefetch" href="/docs/assets/js/118.1b83ec63.js"><link rel="prefetch" href="/docs/assets/js/119.b6aed926.js"><link rel="prefetch" href="/docs/assets/js/12.26dc9b65.js"><link rel="prefetch" href="/docs/assets/js/120.ac9b0bc0.js"><link rel="prefetch" href="/docs/assets/js/121.0781c6a6.js"><link rel="prefetch" href="/docs/assets/js/122.44a85c6b.js"><link rel="prefetch" href="/docs/assets/js/123.564c7418.js"><link rel="prefetch" href="/docs/assets/js/124.179736e7.js"><link rel="prefetch" href="/docs/assets/js/125.250b409f.js"><link rel="prefetch" href="/docs/assets/js/126.54faba3d.js"><link rel="prefetch" href="/docs/assets/js/127.8e0f7e04.js"><link rel="prefetch" href="/docs/assets/js/128.f9792382.js"><link rel="prefetch" href="/docs/assets/js/129.1eb7e9db.js"><link rel="prefetch" href="/docs/assets/js/13.23a019b3.js"><link rel="prefetch" href="/docs/assets/js/130.defc9792.js"><link rel="prefetch" href="/docs/assets/js/131.6d5e5e7c.js"><link rel="prefetch" href="/docs/assets/js/132.3966516d.js"><link rel="prefetch" href="/docs/assets/js/133.ca61eea1.js"><link rel="prefetch" href="/docs/assets/js/134.0f272cde.js"><link rel="prefetch" href="/docs/assets/js/135.d14896d4.js"><link rel="prefetch" href="/docs/assets/js/136.e8835ddb.js"><link rel="prefetch" href="/docs/assets/js/137.b395be5d.js"><link rel="prefetch" href="/docs/assets/js/138.093bdf1b.js"><link rel="prefetch" href="/docs/assets/js/139.c4d22691.js"><link rel="prefetch" href="/docs/assets/js/14.6dcda384.js"><link rel="prefetch" href="/docs/assets/js/140.6cb55c78.js"><link rel="prefetch" href="/docs/assets/js/141.ccb695d0.js"><link rel="prefetch" href="/docs/assets/js/142.f5240b82.js"><link rel="prefetch" href="/docs/assets/js/143.6a97d21f.js"><link rel="prefetch" href="/docs/assets/js/144.1c6dd9bc.js"><link rel="prefetch" href="/docs/assets/js/145.88ff61e2.js"><link rel="prefetch" href="/docs/assets/js/146.f767c81c.js"><link rel="prefetch" href="/docs/assets/js/147.b78bc97f.js"><link rel="prefetch" href="/docs/assets/js/148.e6be3a55.js"><link rel="prefetch" href="/docs/assets/js/149.c10cad8b.js"><link rel="prefetch" href="/docs/assets/js/15.80e90df1.js"><link rel="prefetch" href="/docs/assets/js/150.ea7bb337.js"><link rel="prefetch" href="/docs/assets/js/151.0472c7d2.js"><link rel="prefetch" href="/docs/assets/js/152.8c0a6743.js"><link rel="prefetch" href="/docs/assets/js/153.6628ab54.js"><link rel="prefetch" href="/docs/assets/js/154.94deb0ae.js"><link rel="prefetch" href="/docs/assets/js/155.d98bfaf8.js"><link rel="prefetch" href="/docs/assets/js/156.bd406364.js"><link rel="prefetch" href="/docs/assets/js/157.fc796048.js"><link rel="prefetch" href="/docs/assets/js/158.1821d4c7.js"><link rel="prefetch" href="/docs/assets/js/159.ab837be6.js"><link rel="prefetch" href="/docs/assets/js/16.d4b42272.js"><link rel="prefetch" href="/docs/assets/js/160.f8d14c5a.js"><link rel="prefetch" href="/docs/assets/js/161.d373e85c.js"><link rel="prefetch" href="/docs/assets/js/162.e988edcc.js"><link rel="prefetch" href="/docs/assets/js/163.a377815c.js"><link rel="prefetch" href="/docs/assets/js/164.dd3e4f06.js"><link rel="prefetch" href="/docs/assets/js/165.a1cfe945.js"><link rel="prefetch" href="/docs/assets/js/166.540d9813.js"><link rel="prefetch" href="/docs/assets/js/167.e89b904d.js"><link rel="prefetch" href="/docs/assets/js/168.45df53dd.js"><link rel="prefetch" href="/docs/assets/js/169.76780cac.js"><link rel="prefetch" href="/docs/assets/js/17.fee6f3a3.js"><link rel="prefetch" href="/docs/assets/js/170.43845529.js"><link rel="prefetch" href="/docs/assets/js/171.2b2c6589.js"><link rel="prefetch" href="/docs/assets/js/172.352a29c3.js"><link rel="prefetch" href="/docs/assets/js/173.649332bc.js"><link rel="prefetch" href="/docs/assets/js/174.a5855959.js"><link rel="prefetch" href="/docs/assets/js/175.efe307a5.js"><link rel="prefetch" href="/docs/assets/js/176.91c726a6.js"><link rel="prefetch" href="/docs/assets/js/177.8bade476.js"><link rel="prefetch" href="/docs/assets/js/178.053994ee.js"><link rel="prefetch" href="/docs/assets/js/179.d066ce74.js"><link rel="prefetch" href="/docs/assets/js/18.76346048.js"><link rel="prefetch" href="/docs/assets/js/180.882ea896.js"><link rel="prefetch" href="/docs/assets/js/181.a426394e.js"><link rel="prefetch" href="/docs/assets/js/182.d49c59ab.js"><link rel="prefetch" href="/docs/assets/js/183.5d67029d.js"><link rel="prefetch" href="/docs/assets/js/184.4106bc6e.js"><link rel="prefetch" href="/docs/assets/js/185.25827cea.js"><link rel="prefetch" href="/docs/assets/js/186.ea6e0634.js"><link rel="prefetch" href="/docs/assets/js/187.33366edd.js"><link rel="prefetch" href="/docs/assets/js/188.53915d21.js"><link rel="prefetch" href="/docs/assets/js/189.cc3a723c.js"><link rel="prefetch" href="/docs/assets/js/19.45344bed.js"><link rel="prefetch" href="/docs/assets/js/190.4b0275c9.js"><link rel="prefetch" href="/docs/assets/js/191.d3142009.js"><link rel="prefetch" href="/docs/assets/js/192.0599a45d.js"><link rel="prefetch" href="/docs/assets/js/193.5e47f6bd.js"><link rel="prefetch" href="/docs/assets/js/194.23620377.js"><link rel="prefetch" href="/docs/assets/js/195.fca32468.js"><link rel="prefetch" href="/docs/assets/js/196.efef4613.js"><link rel="prefetch" href="/docs/assets/js/197.c32fdab7.js"><link rel="prefetch" href="/docs/assets/js/198.d6ea7c6c.js"><link rel="prefetch" href="/docs/assets/js/199.a0a20830.js"><link rel="prefetch" href="/docs/assets/js/20.3b03f76e.js"><link rel="prefetch" href="/docs/assets/js/200.c7a361b3.js"><link rel="prefetch" href="/docs/assets/js/201.41ac2e81.js"><link rel="prefetch" href="/docs/assets/js/202.01e38cb5.js"><link rel="prefetch" href="/docs/assets/js/203.ae947426.js"><link rel="prefetch" href="/docs/assets/js/204.cc014a33.js"><link rel="prefetch" href="/docs/assets/js/205.a655ebe8.js"><link rel="prefetch" href="/docs/assets/js/206.40e1748c.js"><link rel="prefetch" href="/docs/assets/js/207.b406ccfa.js"><link rel="prefetch" href="/docs/assets/js/208.573223a3.js"><link rel="prefetch" href="/docs/assets/js/209.da02b88d.js"><link rel="prefetch" href="/docs/assets/js/21.f6d80f99.js"><link rel="prefetch" href="/docs/assets/js/210.c8bfa3b2.js"><link rel="prefetch" href="/docs/assets/js/211.890a2735.js"><link rel="prefetch" href="/docs/assets/js/212.fb46bc53.js"><link rel="prefetch" href="/docs/assets/js/22.0cdc13ce.js"><link rel="prefetch" href="/docs/assets/js/23.ef74f4d3.js"><link rel="prefetch" href="/docs/assets/js/24.e36ed569.js"><link rel="prefetch" href="/docs/assets/js/25.4c47c325.js"><link rel="prefetch" href="/docs/assets/js/26.cb59b1f5.js"><link rel="prefetch" href="/docs/assets/js/27.8647b3b5.js"><link rel="prefetch" href="/docs/assets/js/28.ed56511b.js"><link rel="prefetch" href="/docs/assets/js/29.2742d47f.js"><link rel="prefetch" href="/docs/assets/js/3.a2555baa.js"><link rel="prefetch" href="/docs/assets/js/30.a3239934.js"><link rel="prefetch" href="/docs/assets/js/31.42588eb9.js"><link rel="prefetch" href="/docs/assets/js/32.719a76b1.js"><link rel="prefetch" href="/docs/assets/js/33.2abb2d01.js"><link rel="prefetch" href="/docs/assets/js/34.a86bbffb.js"><link rel="prefetch" href="/docs/assets/js/35.af768465.js"><link rel="prefetch" href="/docs/assets/js/36.8744b541.js"><link rel="prefetch" href="/docs/assets/js/37.8fef0518.js"><link rel="prefetch" href="/docs/assets/js/38.42b85d7c.js"><link rel="prefetch" href="/docs/assets/js/39.c278fbba.js"><link rel="prefetch" href="/docs/assets/js/4.ad7f2bad.js"><link rel="prefetch" href="/docs/assets/js/40.59298f87.js"><link rel="prefetch" href="/docs/assets/js/41.b0d1e127.js"><link rel="prefetch" href="/docs/assets/js/42.3dbee268.js"><link rel="prefetch" href="/docs/assets/js/43.a2715259.js"><link rel="prefetch" href="/docs/assets/js/44.847035be.js"><link rel="prefetch" href="/docs/assets/js/45.fe02feed.js"><link rel="prefetch" href="/docs/assets/js/46.ac4440e9.js"><link rel="prefetch" href="/docs/assets/js/47.6606e840.js"><link rel="prefetch" href="/docs/assets/js/48.04980a92.js"><link rel="prefetch" href="/docs/assets/js/49.625343c8.js"><link rel="prefetch" href="/docs/assets/js/5.cdaab8f6.js"><link rel="prefetch" href="/docs/assets/js/50.2e33cbde.js"><link rel="prefetch" href="/docs/assets/js/51.58be953d.js"><link rel="prefetch" href="/docs/assets/js/52.66abfa6d.js"><link rel="prefetch" href="/docs/assets/js/53.15105bdd.js"><link rel="prefetch" href="/docs/assets/js/54.6f8bb17e.js"><link rel="prefetch" href="/docs/assets/js/55.bc190699.js"><link rel="prefetch" href="/docs/assets/js/56.e9a37892.js"><link rel="prefetch" href="/docs/assets/js/57.14211e19.js"><link rel="prefetch" href="/docs/assets/js/58.5caf93f7.js"><link rel="prefetch" href="/docs/assets/js/59.3ea360a0.js"><link rel="prefetch" href="/docs/assets/js/6.b13411ed.js"><link rel="prefetch" href="/docs/assets/js/60.d477deec.js"><link rel="prefetch" href="/docs/assets/js/61.a029fce2.js"><link rel="prefetch" href="/docs/assets/js/62.1ba4d02e.js"><link rel="prefetch" href="/docs/assets/js/63.2e6f3405.js"><link rel="prefetch" href="/docs/assets/js/64.4718591d.js"><link rel="prefetch" href="/docs/assets/js/65.9b4872b7.js"><link rel="prefetch" href="/docs/assets/js/66.99c67b05.js"><link rel="prefetch" href="/docs/assets/js/67.5985996f.js"><link rel="prefetch" href="/docs/assets/js/68.0f623839.js"><link rel="prefetch" href="/docs/assets/js/69.a0def933.js"><link rel="prefetch" href="/docs/assets/js/7.dd805d38.js"><link rel="prefetch" href="/docs/assets/js/70.3b6dad77.js"><link rel="prefetch" href="/docs/assets/js/71.f3bb8828.js"><link rel="prefetch" href="/docs/assets/js/72.356ad745.js"><link rel="prefetch" href="/docs/assets/js/73.51d93cd8.js"><link rel="prefetch" href="/docs/assets/js/74.d5663bc5.js"><link rel="prefetch" href="/docs/assets/js/75.14cb2a1f.js"><link rel="prefetch" href="/docs/assets/js/76.7e24c00e.js"><link rel="prefetch" href="/docs/assets/js/77.3f3412e2.js"><link rel="prefetch" href="/docs/assets/js/78.7bcb9ae0.js"><link rel="prefetch" href="/docs/assets/js/79.3bb21616.js"><link rel="prefetch" href="/docs/assets/js/8.55431145.js"><link rel="prefetch" href="/docs/assets/js/80.67172e15.js"><link rel="prefetch" href="/docs/assets/js/81.90698f6a.js"><link rel="prefetch" href="/docs/assets/js/82.25b4d2d8.js"><link rel="prefetch" href="/docs/assets/js/83.ec790187.js"><link rel="prefetch" href="/docs/assets/js/84.1d37b34a.js"><link rel="prefetch" href="/docs/assets/js/85.1c91c847.js"><link rel="prefetch" href="/docs/assets/js/86.3fb5120c.js"><link rel="prefetch" href="/docs/assets/js/87.dff7350d.js"><link rel="prefetch" href="/docs/assets/js/88.1d0a3110.js"><link rel="prefetch" href="/docs/assets/js/89.9b824348.js"><link rel="prefetch" href="/docs/assets/js/9.9d834a8c.js"><link rel="prefetch" href="/docs/assets/js/90.a948bff7.js"><link rel="prefetch" href="/docs/assets/js/91.f1782f3f.js"><link rel="prefetch" href="/docs/assets/js/92.ffc62adb.js"><link rel="prefetch" href="/docs/assets/js/93.253f292a.js"><link rel="prefetch" href="/docs/assets/js/94.0a362fbe.js"><link rel="prefetch" href="/docs/assets/js/95.b55e1cbc.js"><link rel="prefetch" href="/docs/assets/js/96.f6137ed9.js"><link rel="prefetch" href="/docs/assets/js/98.d798bc62.js"><link rel="prefetch" href="/docs/assets/js/99.0d90f7f2.js">
    <link rel="stylesheet" href="/docs/assets/css/0.styles.4f35daf1.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/docs/" class="home-link router-link-active"><!----> <span class="site-name">计算机基础教程</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/docs/" class="nav-link">
  机器指令
</a></div><div class="nav-item"><a href="/docs/software/" class="nav-link router-link-active">
  软件基础
</a></div><div class="nav-item"><a href="/docs/coder2hacker/" class="nav-link">
  白帽黑客
</a></div><div class="nav-item"><a href="/docs/blockchain/" class="nav-link">
  区块链
</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/docs/" class="nav-link">
  机器指令
</a></div><div class="nav-item"><a href="/docs/software/" class="nav-link router-link-active">
  软件基础
</a></div><div class="nav-item"><a href="/docs/coder2hacker/" class="nav-link">
  白帽黑客
</a></div><div class="nav-item"><a href="/docs/blockchain/" class="nav-link">
  区块链
</a></div> <!----></nav>  <ul class="sidebar-links"><li><a href="/docs/software/" aria-current="page" class="sidebar-link">软件基础</a></li><li><a href="/docs/coder2hacker/" class="sidebar-link">黑客入门</a></li><li><a href="/docs/blockchain/" class="sidebar-link">区块链入门</a></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><p>https://flink.apache.org/</p> <p><img src="https://flink.apache.org/img/flink-home-graphic.png" alt=""></p> <h2 id="intro"><a href="#intro" class="header-anchor">#</a> Intro</h2> <h3 id="architecture"><a href="#architecture" class="header-anchor">#</a> Architecture</h3> <p>https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/concepts/flink-architecture/
<img src="https://nightlies.apache.org/flink/flink-docs-release-1.15/fig/processes.svg" alt=""></p> <h3 id="key-concepts"><a href="#key-concepts" class="header-anchor">#</a> Key Concepts</h3> <h4 id="streams"><a href="#streams" class="header-anchor">#</a> Streams</h4> <p>Obviously, streams are a fundamental aspect of stream processing. However, streams can have different characteristics that affect how a stream can and should be processed. Flink is a versatile processing framework that can handle any kind of stream.</p> <p><strong>Bounded and unbounded streams:</strong>
Streams can be unbounded or bounded, i.e., fixed-sized data sets. Flink has sophisticated features to process unbounded streams, but also dedicated operators to efficiently process bounded streams.</p> <div class="language- extra-class"><pre><code>+ Unbounded streams 
have a start but no defined end. They do not terminate and provide data as it is generated. Unbounded streams must be continuously processed, i.e., events must be promptly handled after they have been ingested. It is not possible to wait for all input data to arrive because the input is unbounded and will not be complete at any point in time. Processing unbounded data often requires that events are ingested in a specific order, such as the order in which events occurred, to be able to reason about result completeness.

+ Bounded streams 
have a defined start and end. Bounded streams can be processed by ingesting all data before performing any computations. Ordered ingestion is not required to process bounded streams because a bounded data set can always be sorted. Processing of bounded streams is also known as batch processing.
</code></pre></div><p><strong>Real-time and recorded streams:</strong>
All data are generated as streams. There are two ways to process the data. Processing it in real-time as it is generated or persisting the stream to a storage system, e.g., a file system or object store, and processed it later. Flink applications can process recorded or real-time streams.</p> <h4 id="state"><a href="#state" class="header-anchor">#</a> State</h4> <p>Every non-trivial streaming application is stateful, i.e., only applications that apply transformations on individual events do not require state. Any application that runs basic business logic needs to remember events or intermediate results to access them at a later point in time, for example when the next event is received or after a specific time duration.
Application state is a first-class citizen in Flink. You can see that by looking at all the features that Flink provides in the context of state handling.</p> <ul><li>Multiple State Primitives:
Flink provides state primitives for different data structures, such as atomic values, lists, or maps. Developers can choose the state primitive that is most efficient based on the access pattern of the function.</li> <li>Pluggable State Backends:
Application state is managed in and checkpointed by a pluggable state backend. Flink features different state backends that store state in memory or in RocksDB, an efficient embedded on-disk data store. Custom state backends can be plugged in as well.</li> <li>Exactly-once state consistency:
Flink’s checkpointing and recovery algorithms guarantee the consistency of application state in case of a failure. Hence, failures are transparently handled and do not affect the correctness of an application.</li> <li>Very Large State:
Flink is able to maintain application state of several terabytes in size due to its asynchronous and incremental checkpoint algorithm.</li> <li>Scalable Applications:
Flink supports scaling of stateful applications by redistributing the state to more or fewer workers.</li></ul> <h4 id="time"><a href="#time" class="header-anchor">#</a> Time</h4> <ul><li>Event-time Mode:
Applications that process streams with event-time semantics compute results based on timestamps of the events. Thereby, event-time processing allows for accurate and consistent results regardless whether recorded or real-time events are processed.</li> <li>Watermark Support:
Flink employs watermarks to reason about time in event-time applications. Watermarks are also a flexible mechanism to trade-off the latency and completeness of results.</li> <li>Late Data Handling:
When processing streams in event-time mode with watermarks, it can happen that a computation has been completed before all associated events have arrived. Such events are called late events. Flink features multiple options to handle late events, such as rerouting them via side outputs and updating previously completed results.</li> <li>Processing-time Mode:
In addition to its event-time mode, Flink also supports processing-time semantics which performs computations as triggered by the wall-clock time of the processing machine. The processing-time mode can be suitable for certain applications with strict low-latency requirements that can tolerate approximate results.</li></ul> <h4 id="other"><a href="#other" class="header-anchor">#</a> Other</h4> <ul><li><p>Checkpoint Storage</p> <p>The location where the State Backend will store its snapshot during a checkpoint (Java Heap of JobManager or Filesystem).</p></li> <li><p>Flink Application Cluster</p> <p>A Flink Application Cluster is a dedicated Flink Cluster that only executes Flink Jobs from one Flink Application. The lifetime of the Flink Cluster is bound to the lifetime of the Flink Application.</p></li> <li><p>Flink Job Cluster</p> <p>A Flink Job Cluster is a dedicated Flink Cluster that only executes a single Flink Job. The lifetime of the Flink Cluster is bound to the lifetime of the Flink Job. This deployment mode has been deprecated since Flink 1.15.</p></li> <li><p>Flink Cluster</p> <p>A distributed system consisting of (typically) one JobManager and one or more Flink TaskManager processes.</p></li> <li><p>Event</p> <p>An event is a statement about a change of the state of the domain modelled by the application. Events can be input and/or output of a stream or batch processing application. Events are special types of records.</p></li> <li><p>ExecutionGraph/Physical Graph</p> <p>A physical graph is the result of translating a Logical Graph for execution in a distributed runtime. The nodes are Tasks and the edges indicate input/output-relationships or partitions of data streams or data sets.</p></li> <li><p>Function</p> <p>Functions are implemented by the user and encapsulate the application logic of a Flink program. Most Functions are wrapped by a corresponding Operator.</p></li> <li><p>Instance</p> <p>The term instance is used to describe a specific instance of a specific type (usually Operator or Function) during runtime. As Apache Flink is mostly written in Java, this corresponds to the definition of Instance or Object in Java. In the context of Apache Flink, the term parallel instance is also frequently used to emphasize that multiple instances of the same Operator or Function type are running in parallel.</p></li> <li><p>Flink Application</p> <p>A Flink application is a Java Application that submits one or multiple Flink Jobs from the main() method (or by some other means). Submitting jobs is usually done by calling execute() on an execution environment.</p> <p>The jobs of an application can either be submitted to a long running Flink Session Cluster, to a dedicated Flink Application Cluster, or to a Flink Job Cluster.</p></li> <li><p>Flink Job</p> <p>A Flink Job is the runtime representation of a logical graph (also often called dataflow graph) that is created and submitted by calling execute() in a Flink Application.</p></li> <li><p>JobGraph / Logical Graph</p> <p>A logical graph is a directed graph where the nodes are Operators and the edges define input/output-relationships of the operators and correspond to data streams or data sets. A logical graph is created by submitting jobs from a Flink Application.</p> <p>Logical graphs are also often referred to as dataflow graphs.</p></li> <li><p>Flink JobManager</p> <p>The JobManager is the orchestrator of a Flink Cluster. It contains three distinct components: Flink Resource Manager, Flink Dispatcher and one Flink JobMaster per running Flink Job.</p></li> <li><p>Flink JobMaster</p> <p>JobMasters are one of the components running in the JobManager. A JobMaster is responsible for supervising the execution of the Tasks of a single job.</p></li> <li><p>JobResultStore</p> <p>The JobResultStore is a Flink component that persists the results of globally terminated (i.e. finished, cancelled or failed) jobs to a filesystem, allowing the results to outlive a finished job. These results are then used by Flink to determine whether jobs should be subject to recovery in highly-available clusters.</p></li> <li><p>Managed State</p> <p>Managed State describes application state which has been registered with the framework. For Managed State, Apache Flink will take care about persistence and rescaling among other things.</p></li> <li><p>Operator</p> <p>Node of a Logical Graph. An Operator performs a certain operation, which is usually executed by a Function. Sources and Sinks are special Operators for data ingestion and data egress.</p></li> <li><p>Operator Chain</p> <p>An Operator Chain consists of two or more consecutive Operators without any repartitioning in between. Operators within the same Operator Chain forward records to each other directly without going through serialization or Flink’s network stack.</p></li> <li><p>Partition</p> <p>A partition is an independent subset of the overall data stream or data set. A data stream or data set is divided into partitions by assigning each record to one or more partitions. Partitions of data streams or data sets are consumed by Tasks during runtime. A transformation which changes the way a data stream or data set is partitioned is often called repartitioning.</p></li> <li><p>Record</p> <p>Records are the constituent elements of a data set or data stream. Operators and Functions receive records as input and emit records as output.</p></li> <li><p>(Runtime) Execution Mode</p> <p>DataStream API programs can be executed in one of two execution modes: BATCH or STREAMING. See Execution Mode for more details.</p></li> <li><p>Flink Session Cluster</p> <p>A long-running Flink Cluster which accepts multiple Flink Jobs for execution. The lifetime of this Flink Cluster is not bound to the lifetime of any Flink Job. Formerly, a Flink Session Cluster was also known as a Flink Cluster in session mode. Compare to Flink Application Cluster.</p></li> <li><p>State Backend</p> <p>For stream processing programs, the State Backend of a Flink Job determines how its state is stored on each TaskManager (Java Heap of TaskManager or (embedded) RocksDB).</p></li> <li><p>Sub-Task</p> <p>A Sub-Task is a Task responsible for processing a partition of the data stream. The term “Sub-Task” emphasizes that there are multiple parallel Tasks for the same Operator or Operator Chain.</p></li> <li><p>Table Program</p> <p>A generic term for pipelines declared with Flink’s relational APIs (Table API or SQL).</p></li> <li><p>Task</p> <p>Node of a Physical Graph. A task is the basic unit of work, which is executed by Flink’s runtime. Tasks encapsulate exactly one parallel instance of an Operator or Operator Chain.</p></li> <li><p>Flink TaskManager</p> <p>TaskManagers are the worker processes of a Flink Cluster. Tasks are scheduled to TaskManagers for execution. They communicate with each other to exchange data between subsequent Tasks.</p></li> <li><p>Transformation</p> <p>A Transformation is applied on one or more data streams or data sets and results in one or more output data streams or data sets. A transformation might change a data stream or data set on a per-record basis, but might also only change its partitioning or perform an aggregation. While Operators and Functions are the “physical” parts of Flink’s API, Transformations are only an API concept. Specifically, most transformations are implemented by certain Operators.</p></li> <li></li></ul> <h2 id="install-deployment"><a href="#install-deployment" class="header-anchor">#</a> install&amp;deployment</h2> <h3 id="local"><a href="#local" class="header-anchor">#</a> local</h3> <p>https://nightlies.apache.org/flink/flink-docs-release-1.15//docs/try-flink/local_installation/
https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/try-flink/flink-operations-playground/
https://nightlies.apache.org/flink/flink-docs-release-1.14//docs/try-flink/local_installation/</p> <h3 id="production"><a href="#production" class="header-anchor">#</a> production</h3> <p>https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/overview/
hdfs</p> <p>https://flink.apache.org/training.html</p> <h2 id="api-libs"><a href="#api-libs" class="header-anchor">#</a> API&amp;Libs</h2> <h3 id="layered-apis"><a href="#layered-apis" class="header-anchor">#</a> Layered APIs</h3> <p><img src="https://nightlies.apache.org/flink/flink-docs-release-1.15/fig/levels_of_abstraction.svg" alt=""></p> <h4 id="stateful-event-driven-applications-processfunctions-events-state-time"><a href="#stateful-event-driven-applications-processfunctions-events-state-time" class="header-anchor">#</a> Stateful Event-Driven Applications - ProcessFunctions(events,state,time)</h4> <p>ProcessFunctions are the most expressive function interfaces that Flink offers. Flink provides ProcessFunctions to process individual events from one or two input streams or events that were grouped in a window. ProcessFunctions provide fine-grained control over time and state. A ProcessFunction can arbitrarily modify its state and register timers that will trigger a callback function in the future. Hence, ProcessFunctions can implement complex per-event business logic as required for many stateful event-driven applications.</p> <div class="language- extra-class"><pre class="language-text"><code>/**
 * Matches keyed START and END events and computes the difference between 
 * both elements' timestamps. The first String field is the key attribute, 
 * the second String attribute marks START and END events.
 */
public static class StartEndDuration
    extends KeyedProcessFunction&lt;String, Tuple2&lt;String, String&gt;, Tuple2&lt;String, Long&gt;&gt; {

  private ValueState&lt;Long&gt; startTime;

  @Override
  public void open(Configuration conf) {
    // obtain state handle
    startTime = getRuntimeContext()
      .getState(new ValueStateDescriptor&lt;Long&gt;(&quot;startTime&quot;, Long.class));
  }

  /** Called for each processed event. */
  @Override
  public void processElement(
      Tuple2&lt;String, String&gt; in,
      Context ctx,
      Collector&lt;Tuple2&lt;String, Long&gt;&gt; out) throws Exception {

    switch (in.f1) {
      case &quot;START&quot;:
        // set the start time if we receive a start event.
        startTime.update(ctx.timestamp());
        // register a timer in four hours from the start event.
        ctx.timerService()
          .registerEventTimeTimer(ctx.timestamp() + 4 * 60 * 60 * 1000);
        break;
      case &quot;END&quot;:
        // emit the duration between start and end event
        Long sTime = startTime.value();
        if (sTime != null) {
          out.collect(Tuple2.of(in.f0, ctx.timestamp() - sTime));
          // clear the state
          startTime.clear();
        }
      default:
        // do nothing
    }
  }

  /** Called when a timer fires. */
  @Override
  public void onTimer(
      long timestamp,
      OnTimerContext ctx,
      Collector&lt;Tuple2&lt;String, Long&gt;&gt; out) {

    // Timeout interval exceeded. Cleaning up the state.
    startTime.clear();
  }
}
</code></pre></div><h4 id="stream-batch-data-processing-datastream-api-streams-windows"><a href="#stream-batch-data-processing-datastream-api-streams-windows" class="header-anchor">#</a> Stream-&amp;Batch Data Processing - DataStream API(streams,windows)</h4> <p>The DataStream API provides primitives for many common stream processing operations, such as windowing, record-at-a-time transformations, and enriching events by querying an external data store. The DataStream API is available for Java and Scala and is based on functions, such as map(), reduce(), and aggregate(). Functions can be defined by extending interfaces or as Java or Scala lambda functions.</p> <div class="language- extra-class"><pre class="language-text"><code>// a stream of website clicks
DataStream&lt;Click&gt; clicks = ...

DataStream&lt;Tuple2&lt;String, Long&gt;&gt; result = clicks
  // project clicks to userId and add a 1 for counting
  .map(
    // define function by implementing the MapFunction interface.
    new MapFunction&lt;Click, Tuple2&lt;String, Long&gt;&gt;() {
      @Override
      public Tuple2&lt;String, Long&gt; map(Click click) {
        return Tuple2.of(click.userId, 1L);
      }
    })
  // key by userId (field 0)
  .keyBy(0)
  // define session window with 30 minute gap
  .window(EventTimeSessionWindows.withGap(Time.minutes(30L)))
  // count clicks per session. Define function as lambda function.
  .reduce((a, b) -&gt; Tuple2.of(a.f0, a.f1 + b.f1));
</code></pre></div><h4 id="high-level-analytics-api-sql-tableapi-dynamic-tables"><a href="#high-level-analytics-api-sql-tableapi-dynamic-tables" class="header-anchor">#</a> High-level Analytics API - SQL/TableAPI(dynamic tables)</h4> <p>Flink features two relational APIs, the Table API and SQL. Both APIs are unified APIs for batch and stream processing, i.e., queries are executed with the same semantics on unbounded, real-time streams or bounded, recorded streams and produce the same results. The Table API and SQL leverage Apache Calcite for parsing, validation, and query optimization. They can be seamlessly integrated with the DataStream and DataSet APIs and support user-defined scalar, aggregate, and table-valued functions.</p> <div class="language- extra-class"><pre class="language-text"><code>SELECT userId, COUNT(*)
FROM clicks
GROUP BY SESSION(clicktime, INTERVAL '30' MINUTE), userId
</code></pre></div><h3 id="advanced-apis"><a href="#advanced-apis" class="header-anchor">#</a> Advanced APIs</h3> <h4 id="stateful-functions-a-platform-independent-stateful-serverless-stack"><a href="#stateful-functions-a-platform-independent-stateful-serverless-stack" class="header-anchor">#</a> Stateful Functions: A Platform-Independent Stateful Serverless Stack</h4> <p>https://nightlies.apache.org/flink/flink-statefun-docs-stable/</p> <h4 id="flink-ml-apache-flink-machine-learning-library"><a href="#flink-ml-apache-flink-machine-learning-library" class="header-anchor">#</a> Flink ML: Apache Flink Machine Learning Library</h4> <p>https://nightlies.apache.org/flink/flink-ml-docs-stable/
https://nightlies.apache.org/flink/flink-ml-docs-release-2.0/docs/try-flink-ml/quick-start/</p> <h3 id="libraries"><a href="#libraries" class="header-anchor">#</a> Libraries</h3> <h4 id="complex-event-processing-cep"><a href="#complex-event-processing-cep" class="header-anchor">#</a> Complex Event Processing (CEP):</h4> <p>Pattern detection is a very common use case for event stream processing. Flink’s CEP library provides an API to specify patterns of events (think of regular expressions or state machines). The CEP library is integrated with Flink’s DataStream API, such that patterns are evaluated on DataStreams. Applications for the CEP library include network intrusion detection, business process monitoring, and fraud detection.</p> <h4 id="dataset-api"><a href="#dataset-api" class="header-anchor">#</a> DataSet API:</h4> <p>The DataSet API is Flink’s core API for batch processing applications. The primitives of the DataSet API include map, reduce, (outer) join, co-group, and iterate. All operations are backed by algorithms and data structures that operate on serialized data in memory and spill to disk if the data size exceed the memory budget. The data processing algorithms of Flink’s DataSet API are inspired by traditional database operators, such as hybrid hash-join or external merge-sort.</p> <h4 id="gelly"><a href="#gelly" class="header-anchor">#</a> Gelly:</h4> <p>Gelly is a library for scalable graph processing and analysis. Gelly is implemented on top of and integrated with the DataSet API. Hence, it benefits from its scalable and robust operators. Gelly features built-in algorithms, such as label propagation, triangle enumeration, and page rank, but provides also a Graph API that eases the implementation of custom graph algorithms.</p> <h2 id="operations"><a href="#operations" class="header-anchor">#</a> Operations</h2> <h3 id="run-your-applications-non-stop-24-7"><a href="#run-your-applications-non-stop-24-7" class="header-anchor">#</a> Run Your Applications Non-Stop 24/7</h3> <p>Machine and process failures are ubiquitous in distributed systems. A distributed stream processors like Flink must recover from failures in order to be able to run streaming applications 24/7. Obviously, this does not only mean to restart an application after a failure but also to ensure that its internal state remains consistent, such that the application can continue processing as if the failure had never happened.</p> <ul><li>Consistent Checkpoints:
Flink’s recovery mechanism is based on consistent checkpoints of an application’s state. In case of a failure, the application is restarted and its state is loaded from the latest checkpoint. In combination with resettable stream sources, this feature can guarantee exactly-once state consistency.</li> <li>Efficient Checkpoints:
Checkpointing the state of an application can be quite expensive if the application maintains terabytes of state. Flink’s can perform asynchronous and incremental checkpoints, in order to keep the impact of checkpoints on the application’s latency SLAs very small.</li> <li>End-to-End Exactly-Once:
Flink features transactional sinks for specific storage systems that guarantee that data is only written out exactly once, even in case of failures.</li> <li>Integration with Cluster Managers:
Flink is tightly integrated with cluster managers, such as Hadoop YARN, Mesos, or Kubernetes. When a process fails, a new process is automatically started to take over its work.</li> <li>High-Availability Setup:
Flink feature a high-availability mode that eliminates all single-points-of-failure. The HA-mode is based on Apache ZooKeeper, a battle-proven service for reliable distributed coordination.</li></ul> <h3 id="update-migrate-suspend-and-resume-your-applications"><a href="#update-migrate-suspend-and-resume-your-applications" class="header-anchor">#</a> Update, Migrate, Suspend, and Resume Your Applications</h3> <p>Streaming applications that power business-critical services need to be maintained. Bugs need to be fixed and improvements or new features need to be implemented. However, updating a stateful streaming application is not trivial. Often one cannot simply stop the applications and restart a fixed or improved version because one cannot afford to lose the state of the application.</p> <p>Flink’s Savepoints are a unique and powerful feature that solves the issue of updating stateful applications and many other related challenges. A savepoint is a consistent snapshot of an application’s state and therefore very similar to a checkpoint. However in contrast to checkpoints, savepoints need to be manually triggered and are not automatically removed when an application is stopped. A savepoint can be used to start a state-compatible application and initialize its state. Savepoints enable the following features:</p> <ul><li>Application Evolution:
Savepoints can be used to evolve applications. A fixed or improved version of an application can be restarted from a savepoint that was taken from a previous version of the application. It is also possible to start the application from an earlier point in time (given such a savepoint exists) to repair incorrect results produced by the flawed version.</li> <li>Cluster Migration:
Using savepoints, applications can be migrated (or cloned) to different clusters.</li> <li>Flink Version Updates:
An application can be migrated to run on a new Flink version using a savepoint.</li> <li>Application Scaling:
Savepoints can be used to increase or decrease the parallelism of an application.</li> <li>A/B Tests and What-If Scenarios:
The performance or quality of two (or more) different versions of an application can be compared by starting all versions from the same savepoint.</li> <li>Pause and Resume:
An application can be paused by taking a savepoint and stopping it. At any later point in time, the application can be resumed from the savepoint.</li> <li>Archiving:
Savepoints can be archived to be able to reset the state of an application to an earlier point in time.</li></ul> <h3 id="monitor-and-control-your-applications"><a href="#monitor-and-control-your-applications" class="header-anchor">#</a> Monitor and Control Your Applications</h3> <p>Just like any other service, continuously running streaming applications need to be supervised and integrated into the operations infrastructure, i.e., monitoring and logging services, of an organization. Monitoring helps to anticipate problems and react ahead of time. Logging enables root-cause analysis to investigate failures. Finally, easily accessible interfaces to control running applications are an important feature.</p> <p>Flink integrates nicely with many common logging and monitoring services and provides a REST API to control applications and query information.</p> <ul><li>Web UI: Flink features a web UI to inspect, monitor, and debug running applications. It can also be used to submit executions for execution or cancel them.</li> <li>Logging: Flink implements the popular slf4j logging interface and integrates with the logging frameworks log4j or logback.</li> <li>Metrics: Flink features a sophisticated metrics system to collect and report system and user-defined metrics. Metrics can be exported to several reporters, including JMX, Ganglia, Graphite, Prometheus, StatsD, Datadog, and Slf4j.</li> <li>REST API: Flink exposes a REST API to submit a new application, take a savepoint of a running application, or cancel an application. The REST API also exposes meta data and collected metrics of running or completed applications.</li></ul></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/docs/assets/js/app.ecfc7657.js" defer></script><script src="/docs/assets/js/2.37e66b58.js" defer></script><script src="/docs/assets/js/97.ec193d7a.js" defer></script>
  </body>
</html>
