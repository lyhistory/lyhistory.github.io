<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>计算机基础教程</title>
    <meta name="description" content="软件开发教程，渗透测试入门教程，区块链入门教程，物联网，大数据">
    
    
    <link rel="preload" href="/docs/assets/css/0.styles.89d6372f.css" as="style"><link rel="preload" href="/docs/assets/js/app.36bb2510.js" as="script"><link rel="preload" href="/docs/assets/js/2.dc5756d7.js" as="script"><link rel="preload" href="/docs/assets/js/51.73d5d894.js" as="script"><link rel="prefetch" href="/docs/assets/js/10.86e66867.js"><link rel="prefetch" href="/docs/assets/js/11.a111b7db.js"><link rel="prefetch" href="/docs/assets/js/12.97e362f9.js"><link rel="prefetch" href="/docs/assets/js/13.367c1351.js"><link rel="prefetch" href="/docs/assets/js/14.5c9d4e81.js"><link rel="prefetch" href="/docs/assets/js/15.1a009ab9.js"><link rel="prefetch" href="/docs/assets/js/16.8768b841.js"><link rel="prefetch" href="/docs/assets/js/17.12531e9a.js"><link rel="prefetch" href="/docs/assets/js/18.07ee6c0e.js"><link rel="prefetch" href="/docs/assets/js/19.cea4acd3.js"><link rel="prefetch" href="/docs/assets/js/20.17a48234.js"><link rel="prefetch" href="/docs/assets/js/21.472bf1ff.js"><link rel="prefetch" href="/docs/assets/js/22.9651eb29.js"><link rel="prefetch" href="/docs/assets/js/23.54cfc90c.js"><link rel="prefetch" href="/docs/assets/js/24.47e291a3.js"><link rel="prefetch" href="/docs/assets/js/25.970dce12.js"><link rel="prefetch" href="/docs/assets/js/26.6a8aa6ad.js"><link rel="prefetch" href="/docs/assets/js/27.56e8bf0d.js"><link rel="prefetch" href="/docs/assets/js/28.2d78d5c0.js"><link rel="prefetch" href="/docs/assets/js/29.f371e4a9.js"><link rel="prefetch" href="/docs/assets/js/3.e8760d78.js"><link rel="prefetch" href="/docs/assets/js/30.2ae1d920.js"><link rel="prefetch" href="/docs/assets/js/31.4e5d3120.js"><link rel="prefetch" href="/docs/assets/js/32.1cdf393e.js"><link rel="prefetch" href="/docs/assets/js/33.48e36f62.js"><link rel="prefetch" href="/docs/assets/js/34.fcd1707a.js"><link rel="prefetch" href="/docs/assets/js/35.a328f912.js"><link rel="prefetch" href="/docs/assets/js/36.d7777939.js"><link rel="prefetch" href="/docs/assets/js/37.1e6c9f8b.js"><link rel="prefetch" href="/docs/assets/js/38.18b89ac5.js"><link rel="prefetch" href="/docs/assets/js/39.8c358b85.js"><link rel="prefetch" href="/docs/assets/js/4.7d1e56e0.js"><link rel="prefetch" href="/docs/assets/js/40.fc7f665e.js"><link rel="prefetch" href="/docs/assets/js/41.f7d80a95.js"><link rel="prefetch" href="/docs/assets/js/42.04c418d8.js"><link rel="prefetch" href="/docs/assets/js/43.827d897d.js"><link rel="prefetch" href="/docs/assets/js/44.8daeeec0.js"><link rel="prefetch" href="/docs/assets/js/45.174b5109.js"><link rel="prefetch" href="/docs/assets/js/46.aa3f12fc.js"><link rel="prefetch" href="/docs/assets/js/47.75d2a37c.js"><link rel="prefetch" href="/docs/assets/js/48.30329849.js"><link rel="prefetch" href="/docs/assets/js/49.d73fe9a7.js"><link rel="prefetch" href="/docs/assets/js/5.540a7edc.js"><link rel="prefetch" href="/docs/assets/js/50.e906cf67.js"><link rel="prefetch" href="/docs/assets/js/52.6a26c67e.js"><link rel="prefetch" href="/docs/assets/js/53.c45d22c0.js"><link rel="prefetch" href="/docs/assets/js/54.0a0b3240.js"><link rel="prefetch" href="/docs/assets/js/6.3d95153c.js"><link rel="prefetch" href="/docs/assets/js/7.4050b435.js"><link rel="prefetch" href="/docs/assets/js/8.47c0ef23.js"><link rel="prefetch" href="/docs/assets/js/9.e4f2ada1.js">
    <link rel="stylesheet" href="/docs/assets/css/0.styles.89d6372f.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/docs/" class="home-link router-link-active"><!----> <span class="site-name">计算机基础教程</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/docs/" class="nav-link">机器指令</a></div><div class="nav-item"><a href="/docs/software/" class="nav-link router-link-active">软件基础</a></div><div class="nav-item"><a href="/docs/coder2hacker/" class="nav-link">渗透测试</a></div><div class="nav-item"><a href="/docs/blockchain/" class="nav-link">区块链</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/docs/" class="nav-link">机器指令</a></div><div class="nav-item"><a href="/docs/software/" class="nav-link router-link-active">软件基础</a></div><div class="nav-item"><a href="/docs/coder2hacker/" class="nav-link">渗透测试</a></div><div class="nav-item"><a href="/docs/blockchain/" class="nav-link">区块链</a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span></span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/docs/software/project_manage/monitor.html#_1-basics" class="sidebar-link">1.Basics</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/docs/software/project_manage/monitor.html#_1-1-visualization" class="sidebar-link">1.1 Visualization</a></li><li class="sidebar-sub-header"><a href="/docs/software/project_manage/monitor.html#_1-2-data-source-compare" class="sidebar-link">1.2 Data source compare</a></li></ul></li><li><a href="/docs/software/project_manage/monitor.html#_2-details" class="sidebar-link">2. Details</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/docs/software/project_manage/monitor.html#_2-1-prometheus" class="sidebar-link">2.1 Prometheus</a></li><li class="sidebar-sub-header"><a href="/docs/software/project_manage/monitor.html#_2-2-influxdb" class="sidebar-link">2.2 influxdb</a></li></ul></li><li><a href="/docs/software/project_manage/monitor.html#_3-monitor-examples" class="sidebar-link">3. Monitor Examples</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/docs/software/project_manage/monitor.html#_3-1-postgresql-monitor" class="sidebar-link">3.1 Postgresql monitor</a></li><li class="sidebar-sub-header"><a href="/docs/software/project_manage/monitor.html#_3-2-node-exporter-server-metrics" class="sidebar-link">3.2 Node Exporter Server Metrics</a></li><li class="sidebar-sub-header"><a href="/docs/software/project_manage/monitor.html#_3-3-server-alive-monitor-http-request-200-ok" class="sidebar-link">3.3 Server alive monitor - http request 200 OK</a></li><li class="sidebar-sub-header"><a href="/docs/software/project_manage/monitor.html#_3-4-more-prometheus-exporter" class="sidebar-link">3.4 More prometheus exporter</a></li><li class="sidebar-sub-header"><a href="/docs/software/project_manage/monitor.html#_3-5-more-monitor-with-prometheus-influxdb" class="sidebar-link">3.5 More Monitor with prometheus|influxdb</a></li><li class="sidebar-sub-header"><a href="/docs/software/project_manage/monitor.html#_3-6-project-monitor-ci-with-jenkins-nothing-to-do-with-prometheus-influxdb" class="sidebar-link">3.6 Project Monitor CI with Jenkins(nothing to do with prometheus&amp;influxdb)</a></li></ul></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><p><a href="/docs/software">回目录</a>  《Monitor》</p> <h2 id="_1-basics"><a href="#_1-basics" class="header-anchor">#</a> 1.Basics</h2> <h3 id="_1-1-visualization"><a href="#_1-1-visualization" class="header-anchor">#</a> 1.1 Visualization</h3> <p>grafana
https://grafana.com/docs/features/panels/graph/
X-axis type: time, series, histogram
https://grafana.com/docs/features/datasources/
https://grafana.com/docs/features/datasources/prometheus/</p> <p>Grafana vs kibana
https://logz.io/blog/grafana-vs-kibana/
https://grafana.com/docs/features/datasources/elasticsearch/</p> <p>Grafana with nginx
Set up domain
Running Grafana behind a reverse proxy http://docs.grafana.org/installation/behind_proxy/</p> <p>tail -f /var/log/grafana/grafana.log</p> <p>?#issues Template variables are not supported in alert queries
Create new chart/graph without using any template variables
/etc/grafana/grafana.ini</p> <p>?#grafana mail: expected single address, got
Resolved by comment out from_name</p> <p>?#could not send email 1: 452 4.3.1 Out of memory</p> <blockquote><p>If you have a lot of messages queued up it could go over the max number of messages per connection. To see if this is the case you can try submitting only a few messages to that domain at a time and then keep increasing the number until you find the maximum number accepted by the server.
https://social.msdn.microsoft.com/Forums/sqlserver/en-US/a1821fec-5109-46e0-8b18-36b96646a5c7/failure-sending-mail?forum=sqlreportingservices</p></blockquote> <p>grafana permission
Add permission, and remember remove all default viewer and editor permission</p> <h3 id="_1-2-data-source-compare"><a href="#_1-2-data-source-compare" class="header-anchor">#</a> 1.2 Data source compare</h3> <p>Elastic / prometheus/ influxdb/ opentsdb /…...
https://prometheus.io/docs/introduction/comparison/
event logging and metrics recording</p> <p><strong>Prometheus vs influxdb</strong>
InfluxDB supports timestamps with up to nanosecond resolution
Prometheus, by contrast, supports the float64 data type with limited support for strings, and millisecond resolution timestamps
Where InfluxDB is better:
●	If you're doing event logging.
●	Commercial option offers clustering for InfluxDB, which is also better for long term data storage.
●	Eventually consistent view of data between replicas.
Where Prometheus is better:
●	If you're primarily doing metrics.
●	More powerful query language, alerting, and notification functionality.
●	Higher availability and uptime for graphing and alerting.</p> <p>InfluxDB is maintained by a single commercial company following the open-core model, offering premium features like closed-source clustering, hosting and support. Prometheus is a fully open source and independent project, maintained by a number of companies and individuals, some of whom also offer commercial services and support.</p> <p><strong>Prometheus vs. OpenTSDB</strong>
OpenTSDB is a distributed time series database based on Hadoop and HBase.</p> <h2 id="_2-details"><a href="#_2-details" class="header-anchor">#</a> 2. Details</h2> <h3 id="_2-1-prometheus"><a href="#_2-1-prometheus" class="header-anchor">#</a> 2.1 Prometheus</h3> <p>https://prometheus.io/docs/introduction/overview/
<img src="/docs/docs_image/software/project_manage/monitor/monitor01.png" alt=""></p> <p>Pull or push?
Scrape config: scrape interval
Reload config(not work?) https://www.robustperception.io/reloading-prometheus-configuration</p> <p>Prometheus    http://localhost:9090
Monitor your applications with Prometheus https://blog.alexellis.io/prometheus-monitoring/</p> <h4 id="_2-1-1-metric-type"><a href="#_2-1-1-metric-type" class="header-anchor">#</a> 2.1.1 Metric type</h4> <p>https://prometheus.io/docs/concepts/metric_types/
Samples: https://gist.github.com/lyhistory/998448f439594d3eec073d7849d713a8
counter, gauge, histogram, summary
Counter increase all the time
Gauge can be negative, decrease or increase</p> <p><strong>Summary vs histogram</strong></p> <div class="language- extra-class"><pre class="language-text"><code>Summary直接统计每个百分位的“数值”【客户端计算】，比如0.5即50%的请求相应时间是多少 （全范围统计，over all time）：
	*****_duration_seconds{quantile=&quot;0.5&quot;}
	*****_duration_seconds_sum
	*****_duration_seconds_count
	*****_duration_seconds_sum/*****_duration_seconds_count	每个请求的平均耗时
而histogram直接反应了不同区间内样本的个数【服务端计算】（后面的区间是覆盖前面的区间）（全范围统计，over all time）
	*****_range_bucket{le=&quot;100&quot;} 小于100秒的请求个数有几个
	*****_range_sum
	*****_range_count
	*****_range_sum/*****_range_count	每个请求的耗时
	histogram计算百分位函数histogram_quantile
	histogram_quantile(0.5, *****_duration_seconds_bucket) 占50%的请求的平均耗时（需要注意的是通过histogram_quantile计算的分位数，并非为精确值，而是通过*****_duration_seconds_bucket和*****_duration_seconds_sum近似计算的结果）

进一步, Over 10m统计：
Summary
	rate(*****_duration_seconds_sum[10m]) / rate(*****_duration_seconds_count[10])
Histogram
	rate(*****_range_sum[10m]) / rate(*****_range_count[10m])
	histogram_quantile(0.5, rate(*****_duration_seconds_bucket[10m])) 这个结果可能因为还有其他label比如responsecode=200/404产生多条记录：过去10分钟，返回200的50%的请求的平均响应时间以及返回404的50%的请求的平均响应时间，如果想获取过去10分钟，返回所有请求之中的50%的请求的平均响应时间，则需要用
	histogram_quantile(0.5, sum(rate(*****_duration_seconds_bucket[10m])) by (le)) 

</code></pre></div><p><img src="/docs/docs_image/software/project_manage/monitor/monitor02.png" alt="">
https://groups.google.com/forum/#!topic/prometheus-developers/VYaiXJCsHxQ
https://yunlzheng.gitbook.io/prometheus-book/parti-prometheus-ji-chu/promql/prometheus-metrics-types
https://www.yangcs.net/prometheus/3-prometheus/functions.html</p> <p>Sample - Summary</p> <p>The Python client doesn't store or expose quantile information at this time
request_processing_seconds_sum
request_processing_seconds_count
rate(request_processing_seconds_sum[25m])/rate(request_processing_seconds_count[25m])</p> <div class="language- extra-class"><pre class="language-text"><code>from prometheus_client.core import GaugeMetricFamily, CounterMetricFamily, REGISTRY
from prometheus_client import start_http_server, Summary
import random
import time
# Create a metric to track time spent and requests made.
REQUEST_TIME = Summary('request_processing_seconds', 'Time spent processing request')
# Decorate function with metric.
@REQUEST_TIME.time()
def process_request(t):
   &quot;&quot;&quot;A dummy function that takes some time.&quot;&quot;&quot;
   time.sleep(t)
if __name__ == '__main__':
   # Start up the server to expose the metrics.
   parser = argparse.ArgumentParser()
   parser.add_argument('-p', '--port', help=&quot;The port the metrics is serving from.&quot;, required=True)
   args = parser.parse_args()
   start_http_server(int(args.port))
   #Test Summary
   while True: process_request(random.randint(60,600))

</code></pre></div><p>Sample - histogram</p> <div class="language- extra-class"><pre class="language-text"><code>request_latency_seconds_bucket
request_latency_seconds_bucket[10m]
histogram_quantile(0.99, request_latency_seconds_bucket)
histogram_quantile(0.99, rate(request_latency_seconds_bucket[10m]))
histogram_quantile(0.99, sum(rate(request_latency_seconds_bucket[10m])) by (le))

##DEFAULT_BUCKETS = (.005, .01, .025, .05, .075, .1, .25, .5, .75, 1.0, 2.5, 5.0, 7.5, 10.0, INF)
INF = float(&quot;inf&quot;)
# Create a metric to track time spent and requests made.
REQUEST_TIME = Summary('request_processing_seconds', 'Time spent processing request')

# Decorate function with metric.
@REQUEST_TIME.time()
def process_request(t):
	&quot;&quot;&quot;A dummy function that takes some time.&quot;&quot;&quot;
	print(str(t))
	time.sleep(t)
if __name__ == '__main__':
	# Start up the server to expose the metrics.
	parser = argparse.ArgumentParser()
	parser.add_argument('-p', '--port', help=&quot;The port the metrics is serving from.&quot;, required=True)
	args = parser.parse_args()
	start_http_server(int(args.port))
	#Test Summary
	MY_BUCKETS = (30.0,40.0,50.0,60.0,70.0,80.0,90.0,100.0, INF)
	h = Histogram(name='request_latency_seconds', documentation='Description of histogram',buckets=MY_BUCKETS)
	while True:
    	t = random.randint(20,110)
    	h.observe(t)
    	process_request(t)

</code></pre></div><p><img src="/docs/docs_image/software/project_manage/monitor/monitor03.png" alt=""></p> <p><strong>Visualize on grafana</strong>
https://yunlzheng.gitbook.io/prometheus-book/part-ii-prometheus-jin-jie/grafana/grafana-panels/use_graph_panel</p> <p><img src="/docs/docs_image/software/project_manage/monitor/monitor04.png" alt=""></p> <p>histogram graph:
Be careful, grafana x axis ‘histogram’ mode is meaningless for prometheus, so we need to use “Series” mode instead
count==****_count[pre-le,le]	based on separated buckets
Total == ****_count[,le]	based on le buckets
Demonstrated above with x axis in “Time” Mode</p> <p>Format as “Heatmap” so that it will separate le buckets into [] individual buckets
le[,10] le[,20] ….  ====&gt; le[,10] le[10,20] …...</p> <p>heatmap graph:
https://grafana.com/docs/features/panels/heatmap/
Prometheus Histograms &amp; Grafana Heatmaps https://vimeo.com/289620891
Because each **buckets accumulated over time(buckets here has already been separated into individual buckets), so use increase function to show the ‘rate’ along the time</p> <h4 id="_2-1-2-query-data-type-and-promql"><a href="#_2-1-2-query-data-type-and-promql" class="header-anchor">#</a> 2.1.2 Query data type AND PromQL</h4> <p>Literals:
String
Float/scala
Time series selector:
Instant vector selector
Range vector selector
Basic time series
https://prometheus.io/docs/prometheus/latest/querying/examples/</p> <p>Example: scrape every 15s, 4 request every 1m
http_requests_total
http_requests_total[1m]
rate(http_requests_total[1m])
sum(rate(http_requests_total[1m])) by (instance)
sum(rate(http_requests_total[1m])) by job)
topk(5, sum(rate(http_requests_total[5m])) by (instance))</p> <p>Histogram and summary
https://prometheus.io/docs/practices/histograms/
https://timber.io//blog/promql-for-humans/
https://povilasv.me/prometheus-tracking-request-duration/</p> <h4 id="_2-1-3-metric-and-alert-sample"><a href="#_2-1-3-metric-and-alert-sample" class="header-anchor">#</a> 2.1.3 Metric and Alert sample</h4> <p>Prometheus 监控 Nginx 流量 https://www.cnblogs.com/vovlie/p/Nginx_monitoring.html
http://vearne.cc/archives/11085
https://www.cnblogs.com/SleepDragon/p/10642955.html</p> <p>Exporter
EXPORTERS AND INTEGRATIONS https://prometheus.io/docs/instrumenting/exporters/
MONITORING LINUX HOST METRICS WITH THE NODE EXPORTER https://prometheus.io/docs/guides/node-exporter/</p> <p>Example
http://michaeljones.tech/writing-exporters-for-prometheus/
Coinmarketcap:
https://blog.billyc.io/2017/12/02/a-prometheus-exporter-for-cryptocurrency-values-using-the-coinmarketcap-api/
https://www.robustperception.io/writing-a-jenkins-exporter-in-python</p> <h4 id="_2-1-4-troubleshooting"><a href="#_2-1-4-troubleshooting" class="header-anchor">#</a> 2.1.4 troubleshooting</h4> <p>Prometheus deafult admin dashboard:
Status -&gt; Targets : check status</p> <p>c= GaugeMetricFamily('btc_gauge', 'btc statics',labels=['menu'], value=1000)
File &quot;/usr/lib/python2.7/site-packages/prometheus_client/core.py&quot;, line 212, in <strong>init</strong>
raise ValueError('Can only specify at most one of value and labels.')
ValueError: Can only specify at most one of value and labels.</p> <p><img src="/docs/docs_image/software/project_manage/monitor/monitor05.png" alt=""></p> <p>No token found
This usually means that the output is not valid Prometheus text format. Look for hyphens in metric or label names, or either of those starting with numbers - those are the most common errors.</p> <h4 id="_2-1-5-more"><a href="#_2-1-5-more" class="header-anchor">#</a> 2.1.5 More</h4> <p>Scalability</p> <p>Thanos - a Scalable Prometheus with Unlimited Storage https://www.infoq.com/news/2018/06/thanos-scalable-prometheus</p> <h3 id="_2-2-influxdb"><a href="#_2-2-influxdb" class="header-anchor">#</a> 2.2 influxdb</h3> <h4 id="_2-2-1"><a href="#_2-2-1" class="header-anchor">#</a> 2.2.1</h4> <p>V1.7
https://docs.influxdata.com/influxdb/v1.7/introduction/getting-started/
https://github.com/influxdata/influxdb-python
https://influxdb-python.readthedocs.io/en/latest/api-documentation.html</p> <p>Change port /etc/influxdb/influxdb.conf
Run: influxdb or service start influxdb
Cli: influx -precision rfc3339 -host 127.0.0.1 -port 8086</p> <p>Visualize-table panel
https://grafana.com/docs/features/panels/table_panel/</p> <p>?#data with same timestamp and tags gets overwritten
By design https://github.com/influxdata/influxdb/issues/4150</p> <p>v2
https://v2.docs.influxdata.com/v2.0/get-started/
https://community.influxdata.com/c/getting-started
https://community.influxdata.com/c/influxdb2
https://www.influxdata.com/blog/getting-started-with-influxdb-2-0-scraping-metrics-running-telegraf-querying-data-and-writing-data/
flux rpel https://docs.influxdata.com/flux/v0.24/</p> <p>Key concepts: buckets
https://docs.influxdata.com/flux/v0.24/introduction/getting-started</p> <p>New release https://www.influxdata.com/blog/introducing-the-next-generation-influxdb-2-0-platform/</p> <p>(Optional) Copy the influx and influxd binary to your $PATH
sudo cp influxdb_2.0.0-alpha.8_darwin_amd64/{influx,influxd} /usr/local/bin/</p> <p>influxd --http-bind-address=127.0.0.1:9999</p> <h4 id="_2-2-2-example"><a href="#_2-2-2-example" class="header-anchor">#</a> 2.2.2 Example</h4> <p>Influxdb query last row of all series in a measurement
https://community.influxdata.com/t/influxdb-query-last-row-of-all-series-in-a-measurement/4915/3https://community.influxdata.com/t/influxdb-query-last-row-of-all-series-in-a-measurement/4915
https://stackoverflow.com/questions/29193898/influxdb-getting-only-last-value-in-query/56141349#56141349</p> <div class="language- extra-class"><pre class="language-text"><code>from prometheus_client.core import Metric,GaugeMetricFamily, CounterMetricFamily, REGISTRY
from prometheus_client import Gauge
from prometheus_client import start_http_server
import time
import argparse
import requests
from datetime import datetime,timedelta
from influxdb import InfluxDBClient

class CustomCollector(object):
	def __init__(self):
     	self.client = InfluxDBClient(host='localhost', port=8087, database=&quot;TEST&quot;)
	def collect(self):
    	r = requests.get(&quot;http://localhost/api/GetBankAccount&quot;)
    	#print(r)
    	data = r.json()
    	#print(data)
    	print(len(data[&quot;List&quot;]))
    	metric = Metric(&quot;banks&quot;,&quot;bank list&quot;,&quot;gauge&quot;)
    	index = 0

    	current_time = real_time = datetime.utcnow()
    	points = []
    	for item in data[&quot;List&quot;]:
            	index+=1
            	group='NA'
            	if item[&quot;group&quot;] is not None:
                    	group = item[&quot;group&quot;]
            	metric.add_sample(&quot;bank_&quot;+str(index), value=item[&quot;BALANCE&quot;],labels={&quot;type&quot;:&quot;bank&quot;,'bankname': item[&quot;BANKNAME&quot;],&quot;code&quot;:item[&quot;CODE&quot;],&quot;group&quot;:group})
            	json_body = {
                    	&quot;measurement&quot;: &quot;banklist&quot;,
                    	&quot;time&quot;: real_time.strftime('%Y-%m-%dT%H:%M:%SZ'),
                    	&quot;tags&quot;:{
                            	&quot;code&quot;:item[&quot;CODE&quot;]
                    	},
                    	&quot;fields&quot;: {
                            	&quot;timestamp&quot;: real_time.strftime('%Y-%m-%dT%H:%M:%SZ'),
                            	&quot;balance&quot;: item[&quot;BALANCE&quot;],
                            	&quot;bankname&quot;: item[&quot;BANKNAME&quot;],
                            	&quot;bankcode&quot;:item[&quot;CODE&quot;],
                            	&quot;bankgroup&quot;:group
                    	}
            	}
            	print(&quot;Write points: {0}&quot;.format(json_body))
            	points.append(json_body)
            	current_time = current_time+timedelta(seconds=1)
    	if len(points)&gt;0:
            	self.client.write_points(points)
    	yield metric
if __name__ == '__main__':
	# Start up the server to expose the metrics.
	parser = argparse.ArgumentParser()
	parser.add_argument('-p', '--port', help=&quot;The port the metrics is serving from.&quot;, required=True)

	args = parser.parse_args()
	start_http_server(int(args.port))
	REGISTRY.register(CustomCollector())
while True: time.sleep(60)

</code></pre></div><p><img src="/docs/docs_image/software/project_manage/monitor/monitor06.png" alt=""></p> <p>https://thingsmatic.com/2017/03/02/influxdb-and-grafana-for-sensor-time-series/</p> <h2 id="_3-monitor-examples"><a href="#_3-monitor-examples" class="header-anchor">#</a> 3. Monitor Examples</h2> <h3 id="_3-1-postgresql-monitor"><a href="#_3-1-postgresql-monitor" class="header-anchor">#</a> 3.1 Postgresql monitor</h3> <p>Why pgwatch2?
https://www.cybertec-postgresql.com/en/announcing-pgwatch2-a-simple-but-versatile-postgresql-monitoring-tool/</p> <p>https://github.com/cybertec-postgresql/pgwatch2</p> <p><img src="/docs/docs_image/software/project_manage/monitor/monitor10.png" alt=""></p> <h4 id="_3-1-1-introduction"><a href="#_3-1-1-introduction" class="header-anchor">#</a> 3.1.1 Introduction</h4> <p>1）Project background
For more background on the project motivations and design goals see the original series of blogposts announcing the project:
●	Project announcement
●	Implementation details
●	Feature pack 1
●	Feature pack 2
●	Feature pack 3</p> <p>2）Source Code explain
<img src="/docs/docs_image/software/project_manage/monitor/monitor11.png" alt="">
pgwatch2/Dockerfile</p> <p>pgwatch2/docker-launcher.sh
https://github.com/cybertec-postgresql/pgwatch2/blob/9eb5ac699df9873d2138f94dc35e1ba509dd82a6/docker-launcher.sh</p> <p>Supervisord
http://supervisord.org/</p> <p>pgwatch2/supervisord.conf</p> <p>http://blog.51cto.com/youerning/1714627
https://blog.csdn.net/vbaspdelphi/article/details/53324673
Auto start on system start
/etc/init.d/supervisor
https://serverfault.com/questions/96499/how-to-automatically-start-supervisord-on-linux-ubuntu</p> <h4 id="_3-1-2-setup"><a href="#_3-1-2-setup" class="header-anchor">#</a> 3.1.2 setup</h4> <h5 id="_3-1-2-1-env"><a href="#_3-1-2-1-env" class="header-anchor">#</a> 3.1.2.1 env</h5> <p><img src="/docs/docs_image/software/project_manage/monitor/monitor12.png" alt=""></p> <h5 id="_3-1-2-2-install-upgrade-grafana"><a href="#_3-1-2-2-install-upgrade-grafana" class="header-anchor">#</a> 3.1.2.2 install/upgrade grafana</h5> <p>wget https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-5.2.2-1.x86_64.rpm sudo yum localinstall grafana-5.2.2-1.x86_64.rpm
http://docs.grafana.org/installation/upgrading/</p> <p>sudo yum install https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-5.2.2-1.x86_64.rpm
/etc/grafna/grafana.ini</p> <h5 id="_3-1-2-3-run-integrated-docker-image"><a href="#_3-1-2-3-run-integrated-docker-image" class="header-anchor">#</a> 3.1.2.3 run integrated docker image</h5> <ol><li>run docker
pull
https://hub.docker.com/r/cybertec/pgwatch2/tags/
sudo docker run -d -p 8080:8080 -p 8086:8086 -p 9001:9001 -p 3001:3000 --name pw2 cybertec/pgwatch2
sudo docker exec -ti pw2 /bin/bash
Note: don’t follow instructions given by pgwatch2, failed if using the cmd below, need to check the reason:
<em>sudo docker run -d -p 8080:8080 -p 9001:9001 -p 3001:3000 -e PW2_GRAFANA_BASEURL='http://10.20.70.205:3000' --name pw2</em></li></ol> <p>In order to avoid conflicts with existing grafana, we use host port 3001 mapping to docker grafana 3000,
9001 is for supervisor UI, 8080 is for the web ui, 8086 is for influx db</p> <ol start="2"><li>Postgresql server config
At pgsql server:
pgsql -p 6432
/c oureadb
create role pgwatch2 with login password 'secret';
/i pgwatch2/sql/metric_fetching_helpers/stat_activity_wrapper.sql
CREATE EXTENSION pg_stat_statements;
CREATE EXTENSION plpythonu;
/i pgwatch2/sql/metric_fetching_helpers/stat_statements_wrapper.sql
/i pgwatch2/sql/metric_fetching_helpers/cpu_load_plpythonu.sql</li></ol> <p>Add user to pgbouncer</p> <ol start="3"><li>config supervisor http server</li></ol> <div class="language- extra-class"><pre class="language-text"><code>root@28daac38a798:/# supervisor
supervisorctl  supervisord
root@28daac38a798:/# supervisorctl stop
Error: stop requires a process name
stop &lt;name&gt;         	Stop a process
stop &lt;gname&gt;:*      	Stop all processes in a group
stop &lt;name&gt; &lt;name&gt;  	Stop multiple processes or groups
stop all            	Stop all processes

root@28daac38a798:/# ps -lef|grep &quot;super&quot;
4 S root     	1 	0  0  80   0 - 12459 poll_s 08:55 ?    	00:00:00 /usr/bin/python /usr/bin/supervisord --configuration=/etc/supervisor/supervisord.conf --nodaemon
root@28daac38a798:/# netstat -anp|grep :9001
tcp    	0  	0 0.0.0.0:9001        	0.0.0.0:*           	LISTEN  	1/python
root@28daac38a798:/#
</code></pre></div><p>Modify /etc/supervisor/supervisord.conf	add:
[inet_http_server]
port = 9001
username = user
password = 123
But how to restart with configuration changes or reload?
http://www.onurguzel.com/supervisord-restarting-and-reloading/</p> <p>?# pgwatch2 fatal error
check /var/log/supervisor/</p> <ol start="4"><li>Add postgresql db config at WebUI
http://hostip:8080/dbs
Name: dbname
Host: port: db:
Username: pgwatch2, password: secret</li></ol> <p>Note: by default there is a test database, removing from here is useless, because I find the test database still in influxdb, so from grafana you still can see test in the list, the way to get rid of it is change the Variables config in 4)  from default
SHOW TAG VALUES WITH KEY = &quot;dbname&quot;
To
SHOW TAG VALUES WITH KEY = &quot;dbname&quot;  where &quot;dbname&quot; !~ /(test)+/</p> <ol start="5"><li>grafana config
http://hostip:3000/datasources
Add influxdb datasource:
Influx
InfluxDB
http://localhost:8086
Database: pgwatch2, username: root, password: root
Make it default source, otherwise you have to make changes to all the dashboards to specify the datasource from default to influx</li></ol> <p>User and password is required here, because by default, influxdb disable authentication, pls refer to below how to enable and config with auth enabled</p> <p>Add Monitor script:
https://github.com/cybertec-postgresql/pgwatch2/tree/master/grafana_dashboards/v5</p> <p>Change dashboard setting:
Variables -&gt; edit
Datasource:  select influxdb
Query: change
SHOW TAG VALUES WITH KEY = &quot;dbname&quot;
To
SHOW TAG VALUES WITH KEY = &quot;dbname&quot;  where &quot;dbname&quot; !~ /(test)+/</p> <h5 id="_3-1-2-4-results"><a href="#_3-1-2-4-results" class="header-anchor">#</a> 3.1.2.4 results</h5> <div class="language- extra-class"><pre class="language-text"><code>Available measurements (InfluxDB &quot;tables&quot; with metric info) overview
NB! Metrics that are actually gathered need to be configured for every DB separately - for that open the Web UI config page or modify the &quot;pgwatch2.monitored_host&quot; table directly in the &quot;pgwatch2&quot; database
backends - active, total, waiting sessions
pgbouncer_stats - pgbouncer (1.8+) statistics
bgwriter - pg_stat_bgwriter snapshots
blocking_locks - detailed info on sessions that are waiting
cpu_load - CPU load info acquired via a plpython sproc (/pgwatch2/sql/metric_fetching_helpers/)
db_stats - pg_stat_database snapshots + DB size info
index_stats - pg_stat_user_indexes snapshots
kpi - most important high level metrics
locks - different locktype (page, tuple, ...) counts. NB! for usable data one should set the polling interval very low
locks_mode - different lock-mode (exclusive, share) counts. NB! for usable data one should set the polling interval very low
replication - pg_stat_replication info (including replica lag)
sproc_stats - pg_stat_user_functions snapshots
table_io_stats - pg_statio_user_tables snapshots
stat_statements - pg_stat_statements snapshots (requires the extension)
stat_statements_calls - total query count according to pg_stat_statements
table_bloat_approx_summary - bloat summary for the whole DB (needs pgstattuple extension)
table_stats - pg_stat_user_tables snapshots
wal - pg_current_(xlog_location|wal_lsn) values

For getting started with Grafana in general start here
For learning InfluxDB query language InfluxQL start here
When stuck then additional support and consultations are available from Cybertec here
</code></pre></div><h4 id="_3-1-3-lesson-learned"><a href="#_3-1-3-lesson-learned" class="header-anchor">#</a> 3.1.3 Lesson Learned</h4> <h5 id="_3-1-3-1-auth"><a href="#_3-1-3-1-auth" class="header-anchor">#</a> 3.1.3.1 auth</h5> <p>So many auth in so many places!!!
Grafana - add datasource - Auth</p> <p>This is different for varaires datasource, need to specifiy accoridingly</p> <p>For example, for prometheus, it has a default web portal, basic auth is to protect it from access by non authenticated user,
And also protect from http api call
Securing Prometheus with Basic Auth for Grafana https://www.youtube.com/watch?time_continue=431&amp;v=oPlk0GHYmrE</p> <p>In the influxdb example here, we didn’t user basic auth, because:</p> <ol><li>In latest influxdb, it already removed the web portal</li> <li>Influxdb has its own authentication, by config:
Enable auth will affect current pgwatch2, so we need add deafult user root for pgwatch2</li></ol> <p>Create user admin with password ‘123456’ with all priveleges;
/etc/influxdb/influxdb.conf
After restart,  influx -precision rfc3339 -username admin -password 123456</p> <p><img src="/docs/docs_image/software/project_manage/monitor/monitor14.png" alt=""></p> <h5 id="_3-1-3-2-docker-local-volumes"><a href="#_3-1-3-2-docker-local-volumes" class="header-anchor">#</a> 3.1.3.2 docker local volumes</h5> <p>https://github.com/cybertec-postgresql/pgwatch2/blob/master/Dockerfile
https://dzone.com/articles/demystifying-the-data-volume-storage-in-docker
https://docs.docker.com/engine/reference/commandline/volume_inspect/</p> <p><img src="/docs/docs_image/software/project_manage/monitor/monitor15.png" alt=""></p> <h5 id="_3-1-3-3-influxdb"><a href="#_3-1-3-3-influxdb" class="header-anchor">#</a> 3.1.3.3 influxdb</h5> <p>https://docs.influxdata.com/influxdb/v1.6/query_language/schema_exploration/
#retention policy
https://docs.influxdata.com/influxdb/v1.2/query_language/database_management/#create-retention-policies-with-create-retention-policy，https://community.influxdata.com/t/what-is-the-retention-policy-and-how-exactly-it-work/1080/3
Querying data in a non-DEFAULT retention policy https://www.influxdata.com/blog/tldr-influxdb-tech-tips-april-27-2017/
Retention policies not dropping old data https://community.influxdata.com/t/retention-policies-not-dropping-old-data/4538</p> <p><img src="/docs/docs_image/software/project_manage/monitor/monitor16.png" alt=""></p> <h5 id="_3-1-3-4-shift-to-existing-grafana"><a href="#_3-1-3-4-shift-to-existing-grafana" class="header-anchor">#</a> 3.1.3.4 Shift to existing grafana</h5> <ol><li>PW2_GRAFANA_BASEURL doesn’t work
Need to check scripts</li></ol> <div class="language- extra-class"><pre class="language-text"><code>sudo docker run -d -p 8080:8080 -p 8086:8086 -p 9001:9001 -p 3001:3000 -e PW2_GRAFANA_BASEURL='http://10.20.70.205:3000' --name pw2 cybertec/pgwatch2
</code></pre></div><ol start="2"><li>instructions not clear
check section &quot;To use an existing Grafana installation&quot; in https://github.com/cybertec-postgresql/pgwatch2</li></ol> <h5 id="_3-1-3-5-backup-upgrade"><a href="#_3-1-3-5-backup-upgrade" class="header-anchor">#</a> 3.1.3.5 backup &amp; upgrade</h5> <p>Need to explore and refer to “Updating to a newer Docker version” (https://github.com/cybertec-postgresql/pgwatch2)</p> <h4 id="_3-1-4-trouble-shoot"><a href="#_3-1-4-trouble-shoot" class="header-anchor">#</a> 3.1.4 Trouble shoot</h4> <div class="language- extra-class"><pre class="language-text"><code>cd /tmp/
wget https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-5.2.2-1.x86_64.rpm
sudo yum localinstall grafana-5.2.2-1.x86_64.rpm

git clone https://github.com/cybertec-postgresql/pgwatch2.git
sudo git clone https://github.com/cybertec-postgresql/pgwatch2.git

sudo docker pull cybertec/pgwatch2
sudo docker images

sudo netstat -anp|grep :8080
##sudo docker run -d -p 8080:8080 -p 9001:9001 -p 3001:3000 --name pw2 cybertec/pgwatch2
##sudo docker run -d -p 8080:8080 -p 9001:9001 -p 3001:3000 -e PW2_GRAFANA_BASEURL='http://10.20.70.205:3000' --name pw2 cybertec/pgwatch2
sudo docker run -d -p 8080:8080 -p 8086:8086 -p 9001:9001 -p 3001:3000 --name pw2 cybertec/pgwatch2
sudo docker ps -a

##    sudo vi /etc/grafana/grafana.ini
##   	 ;type = postgres
##   	 ;host = 10.20.70.168:6432
##   	 ;name = oureadb
##   	 ;user = pgwatch2
##   	 # If the password contains # or ; you have to wrap it with trippel quotes. Ex &quot;&quot;&quot;#password;&quot;&quot;&quot;
##   	 ;password = secret

sudo docker exec -ti pw2 /bin/bash
    apt-get install net-tools
    service supervisor status
    ps -lef|grep &quot;super&quot;
   	 /usr/bin/supervisord --configuration=/etc/supervisor/supervisord.conf --nodaemon
    vi /etc/supervisor/supervisord.conf
   	 [inet_http_server]
   	 port = 9001
   	 username = peter
   	 password = 123456
    service supervisor restart
	    influx -precision rfc3339
		influx -precision rfc3339 -username admin -password 123456
   	        show databases
			show grants for root;
			grant all on pgwatch2 to root;
   	        use pgwatch2
			show measurements
			select * from backends limit 1
       SHOW TAG VALUES WITH KEY = &quot;dbname&quot; where &quot;dbname&quot; !~ /(test)+/
	vi /pgwatch2/webpy/pgwatch2_influx.py
		modify influx_connect_params
sudo docker start pw2    
    netstat -anp|grep :9001
    netstat -anp|egrep :8080
    ps -lef|egrep &quot;35|PID&quot;
    ls -l /proc/35/exe
    cat /proc/35/cmdline | xargs -0 echo
    ps -p 35 -o cmd
    vi /etc/grafana/grafana.ini
   	 [server]
   	 protocol = http
   	 cert_file = /pgwatch2/persistent-config/self-signed-ssl.pem
   	 cert_key = /pgwatch2/persistent-config/self-signed-ssl.key

   	 [database]
   	 type = postgres
   	 host = 127.0.0.1:5432
   	 name = pgwatch2_grafana
   	 user = pgwatch2
   	 password = pgwatch2admin

   	 [security]
   	 admin_user = admin
   	 admin_password = pgwatch2admin

   	 [auth.anonymous]
   	 enabled = true

   	 [metrics]
   	 enabled = false

sudo docker top 0c7180296ad6    

sudo systemctl status grafana-server
sudo systemctl start grafana-server
journalctl -xe

telnet 10.20.70.168 6432
journalctl -xe

http://10.20.70.205:8080/dbs
oureadb
10.20.70.168 6432 oureadb pgwatch2 secret

</code></pre></div><p>?# postgresql connection timeout
Test on monitor server(running docker), try to connect use pgql
yum localinstall https://download.postgresql.org/pub/repos/yum/11/redhat/rhel-7-x86_64/pgdg-centos11-11-2.noarch.rpm
yum list postgres*
yum install postgresql11.x86_64
psql -h <IP> -p <Port> -U pgwatch2 -W -d <Database>
Works fine on the host server, it turns out that the docker get network connectivity issue,
Test by wget google.com
https://dataonthego.wordpress.com/2015/09/05/install-postgresql-client-only-2/
https://wiki.postgresql.org/wiki/YUM_Installation#Install_PGDG_RPM_file
https://yum.postgresql.org/repopackages.php
https://stackoverflow.com/questions/20430371/my-docker-container-has-no-internet</Database></Port></IP></p> <p>?# prometheus not work =&gt; caused by server diskspace used up =&gt; caused by pgwatch2 influxdb use up space=&gt;caused by pgwatch metrics preset config(full will scrape too much data)
Server date ahead of real datetime
Root disk space used up
Influxdb used up space
vim /etc/influxdb/influxdb.conf	modify check-interval
du -h /var/lib/influxdb/data
<img src="/docs/docs_image/software/project_manage/monitor/monitor17.png" alt=""></p> <p>?# Grafana did not display the records in the expected order in table
very simple solution :
click on max/average whatever column you want to sort, click it once or twice until the result is sorted in your expected order, then save, so next time when you open it, it will display in expected sort order,
actually what happens is the grafana json file will change to for example:
&quot;legend&quot;: {
&quot;alignAsTable&quot;: true,
&quot;avg&quot;: true,
&quot;current&quot;: true,
&quot;max&quot;: true,
&quot;min&quot;: false,
&quot;rightSide&quot;: true,
&quot;show&quot;: true,
&quot;sideWidth&quot;: 300,
&quot;sort&quot;: &quot;max&quot;,
&quot;sortDesc&quot;: true,
&quot;total&quot;: true,
&quot;values&quot;: true
},
ppl asking and discussing it here
https://community.grafana.com/t/grafana-did-not-display-the-records-in-the-expected-order-in-table/4564
and
https://groups.io/g/grafana/topic/prometheus_data_not_sorted/4314229?p=,,,20,0,0,0::recentpostdate%2Fsticky,,,20,0,0,4314229</p> <h3 id="_3-2-node-exporter-server-metrics"><a href="#_3-2-node-exporter-server-metrics" class="header-anchor">#</a> 3.2 Node Exporter Server Metrics</h3> <h4 id="_3-2-1-linux"><a href="#_3-2-1-linux" class="header-anchor">#</a> 3.2.1 Linux</h4> <p>Install node_exporter released for prometheus and config in prometheus
https://prometheus.io/docs/guides/node-exporter/#installing-and-running-the-node-exporter
Grafana dashboard</p> <p>Check http://<em>.</em>.<em>.</em>:9100/metrics</p> <div class="language- extra-class"><pre class="language-text"><code>OR
building running from source:
go get github.com/prometheus/node_exporter
cd ${GOPATH-$HOME/go}/src/github.com/prometheus/node_exporter
make
./node_exporter

</code></pre></div><p>Add alias, never change original variables,</p> <p>?# node_exporter(latest Version 0.16.0) not showing on dashbaord
Because of naming changed https://www.robustperception.io/new-features-in-node-exporter-0-16-0
Use the latest grafana dashboard https://grafana.com/dashboards/1860
And check from prometheus web portal to confirm the query statement</p> <p>?# # multiple series error
Fixed by itself after a while</p> <p>Not verified link:
http://d-prototype.com/archives/9672</p> <p><img src="/docs/docs_image/software/project_manage/monitor/monitor18.png" alt=""></p> <h4 id="_3-2-2-windows"><a href="#_3-2-2-windows" class="header-anchor">#</a> 3.2.2 Windows</h4> <p>Windows support is removed by node exporter, the wmi_exporter is recommended as a replacement.
https://github.com/martinlindhe/wmi_exporter
https://grafana.com/dashboards/2129</p> <h3 id="_3-3-server-alive-monitor-http-request-200-ok"><a href="#_3-3-server-alive-monitor-http-request-200-ok" class="header-anchor">#</a> 3.3 Server alive monitor - http request 200 OK</h3> <p>Endpoint prob - Blackbox-exporter
https://github.com/prometheus/blackbox_exporter</p> <p>https://cloudprober.org/how-to/external-probe/</p> <p>https://grafana.com/dashboards/5345</p> <p><img src="/docs/docs_image/software/project_manage/monitor/monitor19.png" alt=""></p> <p>Alert
http://docs.grafana.org/alerting/notifications/#all-supported-notifier</p> <h3 id="_3-4-more-prometheus-exporter"><a href="#_3-4-more-prometheus-exporter" class="header-anchor">#</a> 3.4 More prometheus exporter</h3> <p>Btc exporter
https://grafana.com/dashboards/6973
https://github.com/hunterlong/btcexporter</p> <div class="language- extra-class"><pre class="language-text"><code>docker run -it -d -p 9019:9019 -v /opt/btc/btcexporter/addresses.txt:/app/addresses.txt hunterlong/btcexporter

ps -lef|grep “prome”
ls /proc/&lt;PID&gt;/exe
vi /path/prometheus.yml
kill -HUP &lt;PID&gt;
</code></pre></div><p>http://10.20.70.205:9019/metrics</p> <p>how to Customize exporter?</p> <p>promethus lib
https://prometheus.io/docs/instrumenting/writing_exporters/
python
https://github.com/prometheus/client_python#custom-collectors
go
https://redbyte.eu/en/blog/real-time-metrics-using-prometheus-and-grafana/</p> <h3 id="_3-5-more-monitor-with-prometheus-influxdb"><a href="#_3-5-more-monitor-with-prometheus-influxdb" class="header-anchor">#</a> 3.5 More Monitor with prometheus|influxdb</h3> <p>Real Time performance monitor for .NET CORE
.Net Core 2.0+ InfluxDB+Grafana+App Metrics 实现跨平台的实时性能监控 https://www.cnblogs.com/landonzeng/p/7904402.html</p> <p>http request/traffic | web api monitor
nodejs
http://swaggerstats.io/docs.html</p> <p>java perform monitor
https://github.com/stagemonitor/stagemonitor/wiki/Installation</p> <h3 id="_3-6-project-monitor-ci-with-jenkins-nothing-to-do-with-prometheus-influxdb"><a href="#_3-6-project-monitor-ci-with-jenkins-nothing-to-do-with-prometheus-influxdb" class="header-anchor">#</a> 3.6 Project Monitor CI with Jenkins(nothing to do with prometheus&amp;influxdb)</h3> <p>CI-Jenkins
https://jenkins.io/doc/tutorials/</p> <p><img src="/docs/docs_image/software/project_manage/monitor/monitor07.png" alt=""></p> <p>Docker mode:</p> <div class="language- extra-class"><pre class="language-text"><code>docker pull jenkinsci/blueocean
docker run \
  --rm \
  -u root \
  -p 8080:8080 \
  -v jenkins-data:/var/jenkins_home \
  -v /var/run/docker.sock:/var/run/docker.sock \
  -v &quot;$HOME&quot;:/home \
  jenkinsci/blueocean
docker exec -ti 0dc7a2730c43 bash

</code></pre></div><p>Find initial password:
docker log 0dc7a2730c43
UI:
http://192.168.56.101:8080/
Work path:
/var/jenkins_home/workspace</p> <p>Use Maven::
?#maven not found
https://my.oschina.net/u/2450666/blog/844170
https://stackoverflow.com/questions/45777031/maven-not-found-in-jenkins/56833922#56833922</p> <div class="language- extra-class"><pre class="language-text"><code>export MAVEN_HOME=/opt/maven
export PATH=$PATH:$MAVEN_HOME/bin
mvn --version
mvn clean compile
mvn clean install
mvn clean package -P dev
</code></pre></div><p>Use Sonarqube::
https://docs.sonarqube.org/latest/setup/get-started-2-minutes/
Java version requirements: https://docs.sonarqube.org/7.8/requirements/requirements/
java.io.IOException: Cannot run program &quot;sonar-scanner&quot; error=2, No such file or directory
https://docs.sonarqube.org/latest/analysis/scan/sonarscanner-for-jenkins/
Jenkins+sonar+sonar-scanner https://www.jianshu.com/p/27e6ed4f6dbc</p> <p>Start sonar.sh on host machine:
cd /home/test/workspace/sonarqube
./sonarqube-7.8/bin/linux-x86-64/sonar.sh console</p> <p>Install sonarscanner on docker/jenkins
sudo docker cp /home/test/workspace/ApexClear/sourcecode/ 0dc7a2730c43:/home/workspace/</p> <p>Pipline
https://jenkins.io/doc/tutorials/build-a-java-app-with-maven/</p> <hr> <p>ref</p> <p>实战 Prometheus 搭建监控系统 https://www.codercto.com/a/35819.html</p></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/docs/assets/js/app.36bb2510.js" defer></script><script src="/docs/assets/js/2.dc5756d7.js" defer></script><script src="/docs/assets/js/51.73d5d894.js" defer></script>
  </body>
</html>
